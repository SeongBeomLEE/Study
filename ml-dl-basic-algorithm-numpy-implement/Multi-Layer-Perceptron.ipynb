{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-Layer-Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class MulLayer:\n",
    "    def __init__(self, input_dim, hidden_dim):\n",
    "        self.X = None\n",
    "        self.W = np.random.uniform(-1, 1, (input_dim, hidden_dim))\n",
    "        self.grad = None\n",
    "    \n",
    "    def forward(self, X):\n",
    "        self.X = X\n",
    "        return X.dot(self.W)\n",
    "    \n",
    "    def backward(self, dout):\n",
    "        self.grad = np.dot(self.X.T, dout) / len(dout)\n",
    "        return np.dot(dout, self.W.T)\n",
    "\n",
    "class AddLayer:\n",
    "    def __init__(self, hidden_dim):\n",
    "        self.X = None\n",
    "        self.b = np.random.uniform(-1, 1, (1, hidden_dim))\n",
    "        self.grad = None\n",
    "    \n",
    "    def forward(self, X):\n",
    "        self.X = X\n",
    "        return X + self.b\n",
    "    \n",
    "    def backward(self, dout):\n",
    "        self.grad = np.sum(dout, axis = 0) / len(dout)\n",
    "        return dout\n",
    "\n",
    "class SigmoidLayer:\n",
    "    def __init__(self):\n",
    "        self.X = None\n",
    "\n",
    "    def sigmoid(self, X):\n",
    "        return 1 / (1 + np.exp(-X))\n",
    "\n",
    "    def forward(self, X):\n",
    "        self.X = X\n",
    "        return self.sigmoid(X)\n",
    "    \n",
    "    def backward(self, dout):\n",
    "        grad = self.sigmoid(self.X) * (1 - self.sigmoid(self.X))\n",
    "        return dout * grad\n",
    "\n",
    "class MSELoss:\n",
    "    def forward(self, X, Y):\n",
    "        return np.mean((X - Y.reshape(-1, 1)) ** 2)\n",
    "    def backward(self, X, Y):\n",
    "        return X - Y.reshape(-1, 1)\n",
    "\n",
    "class CrossEntropyLoss:\n",
    "    def __init__(self, classse):\n",
    "        self.classse = classse\n",
    "\n",
    "    def softmax(self, X):\n",
    "        X = np.exp(X - np.max(X))\n",
    "        return X / np.sum(X, 1).reshape(-1, 1)\n",
    "\n",
    "    def forward(self, X, Y):\n",
    "        epsilon = 1e-10\n",
    "        Y = np.eye(self.classse)[Y]\n",
    "        X = self.softmax(X)\n",
    "        return -np.mean(Y * np.log(X + epsilon))\n",
    "    \n",
    "    def backward(self, X, Y):\n",
    "        Y = np.eye(self.classse)[Y]\n",
    "        X = self.softmax(X)\n",
    "        return X - Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression\n",
    "\n",
    "- MSE를 손실함수로 사용하고, 경사하강법을 이용하여 모델의 가중치를 업데이트\n",
    "\n",
    "- 경사하강법은 SGD가 아닌 전체 데이터를 사용하는 Batch GD를 사용함\n",
    "\n",
    "- 활성화 함수는 Sigmoid를 사용함\n",
    "\n",
    "- Loss = MSE = (Y - Y_hat)**2 / N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 생성\n",
    "X = np.random.randn(1000, 10)\n",
    "W = np.random.rand(10)\n",
    "b = np.random.rand()\n",
    "\n",
    "Y = X.dot(W) + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 정의\n",
    "W1 = MulLayer(input_dim=10, hidden_dim = 128)\n",
    "b1 = AddLayer(hidden_dim = 128)\n",
    "A1 = SigmoidLayer()\n",
    "\n",
    "W2 = MulLayer(input_dim=128, hidden_dim = 64)\n",
    "b2 = AddLayer(hidden_dim = 64)\n",
    "A2 = SigmoidLayer()\n",
    "\n",
    "W3 = MulLayer(input_dim=64, hidden_dim = 1)\n",
    "b3 = AddLayer(hidden_dim = 1)\n",
    "\n",
    "creterion = MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 100 | Loss : 0.6955597137341711\n",
      "Epoch: 200 | Loss : 0.29999259860306926\n",
      "Epoch: 300 | Loss : 0.24426497636646774\n",
      "Epoch: 400 | Loss : 0.22722615241701571\n",
      "Epoch: 500 | Loss : 0.2159969070529418\n",
      "Epoch: 600 | Loss : 0.20650455402936926\n",
      "Epoch: 700 | Loss : 0.19804849299560867\n",
      "Epoch: 800 | Loss : 0.1903988349115784\n",
      "Epoch: 900 | Loss : 0.18341942353260024\n",
      "Epoch: 1000 | Loss : 0.17700912107396394\n"
     ]
    }
   ],
   "source": [
    "# 학습\n",
    "lr = 0.01\n",
    "epochs = 1000\n",
    "layers = [W1, b1, A1, W2, b2, A2, W3, b3]\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    # 순전파\n",
    "    output = X\n",
    "    for layer in layers:\n",
    "        output = layer.forward(output)\n",
    "    \n",
    "    # Loss 계산\n",
    "    loss = creterion.forward(output, Y)\n",
    "    if epoch % 100 == 0:\n",
    "        print(f\"Epoch: {epoch} | Loss : {loss}\")\n",
    "\n",
    "    # 역전파\n",
    "    dout = creterion.backward(output, Y)\n",
    "    for layer in layers[::-1]:\n",
    "        dout = layer.backward(dout)\n",
    "\n",
    "    # 업데이트\n",
    "    for layer in layers:\n",
    "        if layer.__class__.__name__ == 'MulLayer':\n",
    "            layer.W -= lr * layer.grad\n",
    "        if layer.__class__.__name__ == 'AddLayer':\n",
    "            layer.b -= lr * layer.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification\n",
    "\n",
    "- CE를 손실함수로 사용하고, 경사하강법을 이용하여 모델의 가중치를 업데이트\n",
    "\n",
    "- 경사하강법은 SGD가 아닌 전체 데이터를 사용하는 Batch GD를 사용함\n",
    "\n",
    "- 활성화 함수는 Sigmoid를 사용함\n",
    "\n",
    "- Loss = CE = -(Y * log(Y_hat)) / N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 생성\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "data = load_iris()\n",
    "\n",
    "X = data.data\n",
    "Y = data.target\n",
    "\n",
    "num_feature = len(data.feature_names)\n",
    "classse = len(data.target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 정의\n",
    "W1 = MulLayer(input_dim=num_feature, hidden_dim = 128)\n",
    "b1 = AddLayer(hidden_dim = 128)\n",
    "A1 = SigmoidLayer()\n",
    "\n",
    "W2 = MulLayer(input_dim=128, hidden_dim = 64)\n",
    "b2 = AddLayer(hidden_dim = 64)\n",
    "A2 = SigmoidLayer()\n",
    "\n",
    "W3 = MulLayer(input_dim=64, hidden_dim = classse)\n",
    "b3 = AddLayer(hidden_dim = classse)\n",
    "\n",
    "creterion = CrossEntropyLoss(classse=classse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 100 | Loss : 0.19954912629044208 | Acc : 0.88\n",
      "Epoch: 200 | Loss : 0.1574075774026065 | Acc : 0.9733333333333334\n",
      "Epoch: 300 | Loss : 0.13434658445165368 | Acc : 0.9733333333333334\n",
      "Epoch: 400 | Loss : 0.11858732987061522 | Acc : 0.98\n",
      "Epoch: 500 | Loss : 0.10632626955306948 | Acc : 0.98\n",
      "Epoch: 600 | Loss : 0.09610901291170415 | Acc : 0.9866666666666667\n",
      "Epoch: 700 | Loss : 0.0873418788424845 | Acc : 0.9866666666666667\n",
      "Epoch: 800 | Loss : 0.07982543850064526 | Acc : 0.9866666666666667\n",
      "Epoch: 900 | Loss : 0.07347619696158178 | Acc : 0.9866666666666667\n",
      "Epoch: 1000 | Loss : 0.06815821632355323 | Acc : 0.9866666666666667\n"
     ]
    }
   ],
   "source": [
    "# 학습\n",
    "lr = 0.01\n",
    "epochs = 1000\n",
    "layers = [W1, b1, A1, W2, b2, A2, W3, b3]\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    # 순전파\n",
    "    output = X\n",
    "    for layer in layers:\n",
    "        output = layer.forward(output)\n",
    "    \n",
    "    # Loss 계산\n",
    "    loss = creterion.forward(output, Y)\n",
    "    if epoch % 100 == 0:\n",
    "        print(f\"Epoch: {epoch} | Loss : {loss} | Acc : {sum(np.argmax(output, axis=1) == Y) / len(Y)}\")\n",
    "\n",
    "    # 역전파\n",
    "    dout = creterion.backward(output, Y)\n",
    "    for layer in layers[::-1]:\n",
    "        dout = layer.backward(dout)\n",
    "\n",
    "    # 업데이트\n",
    "    for layer in layers:\n",
    "        if layer.__class__.__name__ == 'MulLayer':\n",
    "            layer.W -= lr * layer.grad\n",
    "        if layer.__class__.__name__ == 'AddLayer':\n",
    "            layer.b -= lr * layer.grad"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5836ffa1101046057468fdfe98fbd6981fde0b239b5104b10a8f4b084de20616"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
