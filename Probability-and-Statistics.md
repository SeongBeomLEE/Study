# 확률과 통계
## 통계학이란
- 통계학이란 한마디로 표현하면, 모집단의 특성을 잘 대표하는 표본을 뽑아서 그 표본에 있는 제한된 정보를 이용하여 미지의 값인 모집단의 특성인 모수들에 대하여 통계적 추론을 하고자 하는 학문임

## 평균과 중앙값
- 평균은 모든 데이터를 다 더해서 데이터의 수로 나눈 값을 의미함
- 중앙값은 모든 데이터를 크기 순으로 나열하여 정확히 50%에 위치하는 값을 의미함
- 따라서 평균은 이상치에 민감하지만, 중앙값은 평균보다 덜 민감함

## 심슨의 역설
- 부분에서 성립하던 성질이 전체에서는 성립하지 않는 것을 심슨의 역설이라고 함
- 예를 들어 남자:9 여자:1의 비율을 가지는 지역이 있다고 했을 때, 이 지역을 성별을 나누지 않고 분석하면 남자의 특성을 가진다고 해석할 수 있음, 하지만 성별을 나누어 분석하면 각 성별마다의 특성이 존재한다는 것을 확인할 수 있을 것임
- 이처럼 부분에서 성립하던 성질이 전체에서는 성립하지 않을 수도 있기 때문에 분석시에는 부분적으로 나눠서 분석을 하는 것이 중요함

## 상관 관계와 인과 관계
- 상관 관계는 원인과 결과에 상관 없이 특정 변수가 변할 때 다른 변수도 함께 변하면 두 변수는 서로 상관 관계에 있다고 함(A 상승or하락 - B 상승or하락 <- 양의 상관 관계 / A 상승or하락 - B 하락or상승 <- 음의 상관 관계)
- 인과 관계는 상관 관계를 지니는 두 변수에 시간적 우선 순위가 존재하여 원인과 결과로 설명할 수 있을 때 두 변수는 인과 관계를 가진다고 함(상관 관계는 인과 관계의 필요 조건 중 하나임)

## 선험적 확률과 경험적 확률
- 선험적 확률(수학적 확률)은 각 사건이 발생하는 확률이 같다는 것으로, 시행에 대해서 일어날 수 있는 모든 경우의 수가 N가지이고, 어떤 사건이 일어나는 경우의 수가 K가지일 떼, 어떤 사건이 일어나는 확률이 K/N인 것을 뜻함, 즉 경험하지 않고도 이론적으로 미리 알 수 있는 확률을 의미함(주사위 같은)

- 경험적 확률은 같은 시행을 여러 번 반복하여 얻을 수 있는 횟수를 통해 나오는 확률을 의미함, 즉 시물레이션이나 실험을 통해서 나오는 확률임, 이런 확률이 필요한 이유는 모든 사건을 수학적 확률로 계산할 수 없기 때문임(화산이 폭발할 확률을 우리가 수학적으로 계산할 수 없음, 그러나 시물레이션을 통해서 확률을 계산할 수는 있을 것임)

## 기댓값, 분산, 공분산, 상관계수, 공분산 행렬
- 기댓값은 확률적 사건에 대한 평균 값으로, 사건이 일어나서 얻는 값과 그 사건이 일어날 확률을 곱한 것을 모든 사건에 대해 합한 값으로, 어떤 확률적 사건에 대한 평균의 의미를 갖음

- 분산은 데이터가 평균으로 부터 얼마나 퍼져있는지를 가늠할 수 있는 값으로, 데이터의 분포를 알 수 있음

- 분산은 우리가 한 예측이 얼마나 불확실한지의 정도의 표현으로도 사용 가능함, 왜냐하면 분산이 작다는 것은 분포의 폭이 작다는 것이고 분산이 크다는 것은 분포의 폭이 넓다는 것임, 분포의 폭이 넓을 수록 우리가 예측하고자 하는 값의 불확실성은 높아진다고 볼 수 있음(정답이 평균이라고 했을 때 평균이 아닌 다른 값이 선택될 확률이 높아지기 때문에)

- 공분산은 두 변수 간의 상관 관계를 파악하는데 쓰이는 개념으로, 각 변수의 편차를 서로 곱한 것의 평균임

- 그런데 공분산 자체가 X와 Y의 단위의 크기에 영향을 받기 때문에, 이를 보완하고자 공분산을 표준편차로 니누어 표준화 한 것이 상관 계수임

- 공분산 행렬은 여러 개의 변수가 서로 어떤 관계를 가지는지 나타내고자, 공분산을 행렬로 구한 것이 바로 공분산 행렬임(대각 행렬은 분산, 나머지 부분은 각 변수 간의 공분산 값임)

## 확률 변수, 확률 분포, 확률 밀도 함수, 누적 분포 함수, 확률 질량 함수, 누적 질량 함수
- 확률 변수는 특정 확률로 발생하는 각각의 결과(확률값)를 수치적 값으로 표현한 변수(실수값)를 의미함, 따라서 어떻게 보면 확률 변수는 결과 값을 하나의 실수값으로 변환해주기 때문에 함수 식이라고 표현할 수도 있음

- 각 확률 변수의 값들은 발생할 확률 값들이 가지고 있으며, 이 확률 변수가 가지는 확률값을 분포로 표현한 것이 확률 분포임, 즉 획률 분포는 샘플(관측치)들이 가질 수 있는 수치 값을 각각 0과 1 사이의 확률로 표현할 때, 이 확률 값들의 패턴이라고 볼 수 있음

- 확률 변수를 특정한 확률 값으로 표현하는데 사용되는 식이 확률 함수라고 볼 수 있음

- 모든 사건 -실험-> 확률 변수(동일한 사건은 같은 확률 변수를 가짐(앞뒷, 뒷앞)) -> 확률 함수(확률 변수가 발생할 확률을 표현하는 식) -> 확률 분포(확률의 분포)

- 모든 확률 분포는 한 개 이상의 모수를 가지고 있으며(평균, 분산 등), 이는 확률 분포의 모양을 결정함(정규 분포의 경우 평균과 분산 2개의 모수가 있고 이들이 정규 분포의 모양을 결정), 많은 경우 분포의 모수는 알려져 있지 않으며 모수를 추측해보는 과정을 통계학에서 추정이라고 함

- 확률 밀도 함수(PDF)는 연속 확률 변수의 분포(확률)를 나타내는 함수

- 누적 분포 함수(CDF)는 연속형 분포의 주어진 확률 변수가 특정 값보다 작거나 같은 확률을 나타내는 함수

- 확률 질량 함수(PMF)는 이산 확률 변수의 분포(확률)를 나타내는 함수

- 누적 질량 함수(CMF)는 이산형 분포의 주어진 확률 변수가 특정 값보다 작거나 같은 확률을 나타내는 함수

## 이항 분포
- 이항 분포는 동전 던지기의 앞면 혹은 뒷면과 같이 두 가지 사건만 일어날 수 있는 경우에 대해 기대해 볼 수 있는 분포

- 이항 분포는 특정 조건을 만족하 분포의 모양이 정규 분포에 근사해짐

- 이항 분포는 연속된 n번 독립적 시행에서 각 시행이 확률 p를 가질 때의 이산 확률 분포

- 이항분포의 확률질량함수의 식은 아래와 같음, 식의 의미는 성공 확률 p를 갖는 이벤트를 n번의 시행 했는데, 그 중 성공한 횟수는 k번 이라는 것임, 그러면 자연스럽게 1-p의 시행 횟수는 n-k가 됨

- $ \binom n k p^k(1-p)^{n-k} $

- 이항분포는 p라는 획률을 가지는 사건을 연속 n회 시행했을 때, 0~n회 사이의 시행 중 우리가 원하는 사건이 몇번 발생할 지를 확률적으로 기술해놓은 분포라고 할 수 있음

- 총 시행 횟수가 n, 성공 확률이 p인 이항 분포의 평균 값은 np, 분산은 np(1-p)

- 수학자들은 이항 분포가 정규분포의 형태와 유사해질수 있다고 볼 수 있는 기준을 np와 $\sqrt{np(1-p)}$가 5보다 클때로 보며, 이때 평균이 np이고 분산이 np(1-p)인 정규분포를 따른다고 함

## 기하 분포
- 기하 분포는 성공 혹은 실패의 두 가지 경우의 수로 구성된 시행을 연달아 수행 시 처음 성공할 때 까지 시도한 횟수 k에 대한 분포(성공할 확률이 높은 시행은 k가 낮은 값일 때 더 큰 값을 가질 것임)

- 성공 확률이 p인 시행에 대해 k번 시행 후 첫번째 성공을 얻을 확률은 다음과 같으며, 식을 보면 (1-p)를 매 항마다 계속해서 곱해나간다는 것을 알 수 있음(계속 틀렸으니깐 당연한거임)

- $(1-p)^{k-1}p$

- 기하 분포에서 보여주는 것은 성공 확률이 p일 때 k번째 처음으로 성공할 수 있는 확률을 의미함
    
- 분포의 모양을 바탕으로 현재 내가 하고 있는 일이 언제 쯤에 성공할 지 대략적인 감을 알 수 있음, 즉 성공 확률이 높은 행동일 수록 초기에 매우 큰 값을 가지고, 그 뒤에 제일 처음으로 성공할 확률이 낮아지지 점점 급감할 것임, 반대로 성공 확률이 낮은 행동은 언제 성공할지 누구도 모르니 전체적으로 평탄한 모양을 기질 것임

- 합격 확률이 0.2인 시험이 있을 때, 이 시험을 3번째 만에 합격할 확률은?
    - 0.2 + (0.8)^1*0.2 + (0.8)^2*0.2 = 0.448
    - 1, 2, 3번째에 성공할 확률들을 다 구해서 더하면 됨


## 포아송 분포
- 이항분포에서 n이 너무 크고 p가 너무 작은 경우에 이항 분포의 확률분포를 근사적으로 계산하기 위해서는 극한값을 이용한 새로운 형태의 분포를 제시하는 것이 바람직하고, 이 새로운 형태의 분포가 바로 포아송 분포

- 포아송 분포는 수 많은 사건 중(n->무한) 특정한 사건이 발생할 확률이 매우 적은(즉, p -> 0)확률 변수가 갖는 분포

- 정해진 시간 안에 어떤 사건이 일어날 횟수에 대한 기댓값을 $\lambda$ 라고 했을 때, 그 사건이 n회 일어날 확률은 다음과 같음

- $f(n;\lambda) = \frac{\lambda^n e^{-\lambda}}{n!}$

## 지수 분포
- 사건이 서로 독립적일 때, 일정 시간동안 발생하는 사건의 횟수가 포아송 분포를 따른다면, 다음 사건이 일어날 때 까지의 대기 시간은 지수 분포를 따름

- 포아송 분포는 단위 시간동안 어떤 사건이 평균적으로 $\lambda$ 회 발생한다고 했을 때, 단위시간동안 사건이 k번 일어날 확률에 대한 분포를 지칭

- 그러면 여기서 다음 사건이 처음 일어나는 때 까지 걸리는 시간에 대한 분포를 구할 때는 지수 분포를 사용

## 정규 분포
- 어떤 값을 중심으로 대칭적으로 분포하며 중심에서 멀어질수록 도수가 작아지는 종 모양의 분포

## 중심극한정리
- 모집단의 분포의 모양에 상관 없이 표본 평균의 평균은 정규 분포를 따른다는 정의로 해당 정의를 이용해 모집단의 모수인 평균을 통계적으로 추론할 수 있고, 모집단의 평균을 알면 모집단의 특성을 추론할 수 있기 때문에 중요한 정의임

- 여기서 또 신기한 점은 표본을 추출하는 모집단이 서로 독립적이라면, 여러개의 서로 다른 모집단에서 표본을 뽑더라도 표본 평균의 평균은 정균 분포를 따르게 됩니다. (랴푸노프 중심극한정리)

- 그리고 대체적으로 표본을 비교할 때 평균을 많이 사용하기 때문에, 중심극한정리를 염구해두고 만든 많은 이론들이 있어서 중요한 정의임

## 카이제곱분포
- 표준정균분포를 따르는 확률 변수들을 k개 샘플링하고, 그 값들을 제곱합하여 히스트그램으로 나타낸 분포(회귀에서도 에러 값을 제곱하하여 에러를 표현함)

- 카이제곱분포 또한 중심극한정리에 의해서 k의 수가 커지면 정균분포를 따르게 됨

- 카이제곱 분포는 오차(error) 혹은 편차(deviation)를 분석할 때 도움을 받을 수 있는 분포이기 때문에 사용됨

- 여기서 중요한 점은 우리가 보통 error를 정규분포로 설계한다는 점을 이해해야함(회귀 분석의 가정인 정규성)

- 적합도 검정은 독립변수가 하나이고 이론적으로 기대되는 빈도의 분포(frequency distribution)와 관찰한 빈도의 분포를 비교하기 위해 사용

- 교차 분석은 범주형 변수가 여러 개인 경우에 적용하는 분석 방법, 교차 분석의 목적은 여러 범주형 변수의 범주 간 차이가 기댓값에서 유의하게 벗어나는지 확인하는 것

## 모집단, 모수, 표본, 표준 오차
- 모집단은 정보를 얻고자 하는 관심 대상의 전체 집합을 의미

- 모수는 모집단의 특성을 의미, 우리는 전체 집단의 모든 데이터를 알지 못한더라도 수학적으로 그 분포를 기술할 수 있는 특성값을 알 수만 있다면, 비슷하게 모집단의 특성을 통계적으로 확인할 수 있는데, 여기서 특성치들을 우리는 모수라고하며, 모집단의 특성을 나타내는 모수를 파악하여 모집단의 특성을 파악하고자하는 것이 목표

- 표본이란 모집단의 부분집합을 의미

- 표본을 추출하는 이유는, 우리가 모집단 전체에 대해 검사하기에는 비용이 너무 많이 들기 때문임(현실적으로 모집단을 모두 조사하는 것은 불가능함)

- 표본은 매번 추출할 때 마다 그 값이 달라지는 특성을 가지며, 표본으로부터 그 분포의 특성을 나타내는 표본 통계량을 만들 수 있고, 표본 통계량은 모수의 추정치로 볼 수 있으며, 이 값은 항상 오차를 수반함

- 표준 오차란 표본 통계량의 표준 편차를 의미함(여러 개의 표본을 얻어서 거기서 표본 통계량을 얻으면, 그 표본 통계량 값들의 표준 편차를 구할 수 있고, 그 값을 표준 오차라고 함)

- 표준 편차는 모집단의 분포가 얼마나 퍼져있는가를 서술하는 개념이고, 표준 오차는 표본 통계량(추정치)의 평균 값들에 대한 불확실도를 수치화한 개념

## 검정 통계량
- 검정 통계량은 통계적 가설의 진위 여부를 검정하기 위해 표본으로 부터 계산하는 통계량

- 즉, 검정 통계량은 표본 통계량을 2차 가공한 형태로 생각하면 편함, 통계적 가설 진위 여부를 검정한다는 것은 검정통게량의 값이 기준을 벗어나는지 확인하여 세워둔 가설이 틀렸다고 할 수 있는지 확인하는 과정임

## t-value
- 우리가 두 표본 집단간의 평균 차이를 비교한다고 할 때, 우리가 비교하고자하는 평균 값은 표본 평균이기 때문에 오차를 염두해두고 두 표본 간의 차이에 관한 지표를 만들어야 함

- 우리는 표돈 통계량의 불확실성에 대한 값이 표준 오차라는 것을 알고 있음. 

- 따라서 t-value는 표본 평균과 표준 오차(불확실성)를 가지고 계산할 수 있음

- 두 표본 그룹 간의 평균 차이 / 두 그룹간 평균 차이에 대한 불확실도로 t-value를 계산할 수 있으며, 두 그룹간 평균 차이에 대한 불확실도는 각 표본의 분산 값을 각 표본의 개수 n으로 나누어 합한 후 루트를 취한 값으로 계산됨

- t-value는 각 표본의 평균 값의 차이를 표준오차로 나눠준 값으로 정의함

- t-value들의 분포를 계산하여 공식화 한 것이 t-분포라고 할 수 있음

- t-분포를 사용하여 두 표본 간의 차이가 통계적으로 유의미한지를 알 수 있음

## F-value
- F-value는 여러 표본 집단을 비교하기 위한 지표이며, t-value와 마찬가지로 그룹 간의 차이 / 불확실도로 계산할 수 있음, 근데 t-value와 달리 계산 시에 분산을 사용함

- t-value를 제곱한 값이 결국엔 F-value임

- F-value들의 분포를 계산하여 공식화 한 것이 F-분포라고 할 수 있음

## 귀무가설과 대립가설
- 귀무가설은 "새로울 게 없다는 가설"

- 대립가설은 "새로운 것이 있다는 가설"

- 실험을 통해서 새로운 사실을 발견했다는 사실을 입증하기 위해서 귀무가설을 사용하는 이유
    - 참이 아님을 증명하는 것이 참임을 증명하는 것보다 휠씬 쉽기 때문에
    - 귀무가설을 "올바르게" 서술하는 것이 대립가설을 "정확하게" 서술하는 것보다 실패할 가능성이 적음
    - 우리는 모수에 대해서 알 수 없으며, 연구에 있어 주관성이 개입되어선 안되기 때문에

- 위와 같은 이유로 귀무가설을 검증하는데 실패함으로써 간접적으로 새로운 가설, 즉 대립가설에 대해 확인하고자 하는 것임

- 즉, 실험에 어떤 변화가 있다는 사실을 검증하고자 한다면 역으로 가설이 없다고 가정한 뒤에 실험을 진행하는 것임(귀무 가설 설정)

- 변화가 없다는 가설(귀무가설)에 모순이 있다는 것을 발견하게 되면 이것을 근거로 변화가 있다는 사실(대립가설)을 간접적으로 증명할 수 있게 되는 것임

- 귀무가설을 이용한 검증 방법은 무죄 추정의 원칙으로 설명할 수 있음, 무죄 추정 원칙을 따르면 용의자나 피고인은 유죄로 판결이 확정(귀무가설이 기각된 상태)되기 전 까지는 무죄로 추정(귀무가설이 기각되지 않은 상태)하고, 유죄로 판결하기 위해선 피고인이 실제로 무죄라고 가정했을 때 발생할 수 없는 증거나 상황(통계학적으로 유의한 수준)이 뒷받침 되어야 함

- 귀무가설 검증 과정은 오로지 검증 실패에만 주안점을 두는 과정이기 때문에, 귀무가설을 기각할 수 있게 되었다고 해서 대립가설을 증명한 것은 아니라는 점이 중요함

- 대립가설을 간접적으로 이용한 통계적 추론 방법이 신뢰 구간을 이용한 검정 방법

- 대립가설을 직접적으로 이용한 통계적 추론 방법이 베이즈 추론 방법

## p-value
- p-value는 확률값으로써 귀무가설과 현재 얻은 결과가 얼마나 일치(compatible)하는지를 말해주는 값임

- p-value는 검정 통계량에 관한 확률인데, 우리가 얻은 검정 통계량보다 크거나 같은 값을 얻을 수 있을 확률을 의미함(즉 p-value가 0.05 보다 작다는 것은 귀무 가설이 틀릴 확률이 높다는 것을 의미함, 왜냐하면 p-value는 확률 값이니깐 낮은 값이 나오면 현재 값이 나올 확률 자체가 낮다는 것을 의마하고, 이는 귀무 가설이 틀렸다는 것을 의미함)

- 우리가 계산하는 검정 통계량들은 거의 대부분이 귀무가설을 가정하고 얻게 되는 값임

- 두 표본 평균의 차이를 검증한다고 할 때, 두 표본 집단의 모집단은 같다는 가정을 전제함

- "우리가 얻은 데이터에 있는 두 표본 집단이 같은 모집단에서부터 나온거라고 치자, 그랬을 때, 우리가 이런 검정 통계량(가령, t-value)을 얻었는데 이게 얼마나 말이되는거냐?" 이에 대한 해답이 바로 p-value임(따라서 값이 낮다는 것은 말이 될 확률이 낮다는 것을 의미함)

- 표본 통계량(표본 집단의 특성) -가공-> 검정 통계량(표본 통계량을 가지고 통계적 가설의 진위 여부를 판단하기 위한 값, t-value / F-value 등) -가공-> p-value(검정 통계량에 관한 확률, 검정 통계량이 유의미한지 판단하기 위한 값)

- p-value는 효과의 크기(effect size)와 표본의 크기(n 수)의 정보를 한꺼번에 담고 있음(검정 통계량을 압축한 정보)

- 효과의 크기가 커지거나 표본의 크기가 커지거나 둘 중 하나만 변하더라도 p-value는 마치 유의한 차이를 담보할수 있을 것 마냥 작아짐, 즉 실제로 한 모집단에서 두 표본 집단이 나왔음에도 효과의 크기나 표본의 크기가 너무 커서 p-value는 0.05보다 낮을 수 있으며 귀무가설이 기각되어 대립 가설이 채택됨에도 불구하고 대립 가설이 참이 아닐 수도 있음

- 낮은 p-value (통상 0.05 이하)를 얻었다는 것은 귀무 가설과 현재의 실험 결과가 그만큼 일치하지 않는다는 것을 말하는 것이고, 이에 따라 귀무 가설을 기각함

- 귀무가설을 기각할 수 있다는 것은 귀무가설과 현재 얻은 결과가 서로 양립할 수 없음을 의미하며, 우리는 양립할 수 있는 정도를 표현하기 위해서 p-value를 사용 (p-value가 높다는 것은 두 값은 서로 양립할 수 있음, 낮다는 것은 양립할 수 있는 가능성이 낮다는 것)

## 신뢰 구간
- 표본 통계량에는 항상 불확실성은 수반하기 때문에(샘플링), 그나마 내가 확실히 말할 수 있는 정도를 구간으로 표현하며, 이를 신뢰 구간이라고 부르고, 우리는 이를 이용해 통계적 추정을 함

- 즉, 내가 지금 추출한 표본 평균은 모평균으로부터 2 * 표준 오차(SEM, 표본 평균의 표준 편차) 범위 안에 95% 확률로 들어온다라고 설명하는 것

- 여기서 95% 라는 의미는 100번 정도 샘플링을 했을 때, 우리가 표본 평균을 바탕으로 모평균을 추론했을 때, 그 값이 95번 정도는 해당 신뢰 구간안에 들어온다는 의미임

- 여기서 95% 는 신뢰 수준

- 2 * 표준 오차(SEM, 표본 평균의 표준 편차) 범위는 신뢰 구간

- p-value는 효과의 크기가 커지거나 표본의 크기가 커지거나 둘 중 하나만 변하더라도 그 값이 매우 작아질 수 있음, 이에 효과의 크기(effect size)를 함께 보여주는 신뢰 구간을 함께 사용하면 p-value를 단점을 개선할 수 있음(가령 두 값의 범위가 매우 작다면 아무리 p-value의 값이 낮더라도 실제로는 유의미한 차이를 낸다고 볼 수는 없을 것임, 이처럼 두 값을 함께 사용하면 더 많은 정보를 확인할 수 있음)

## 1종 오류와 2종 오류
- 1종 오류는 귀무가설이 참인데 잘못 기각할 때 발생하는 오류

- 2종 오류는 귀무가설이 거짓인데 기각하지 않았을 때 발생하는 오류

- 검정은 확률을 기반으로 하기 때문에 어떤 가설 검정도 100% 확실한 것은 없음, 이에 언제나 잘못된 결론을 내릴 가능성이 있음

- 우리가 사건에 대해 다루는 가설은 딱 두가지이다. 이 사건이 일어났거나, 일어나지 않았거나.

- 통계학이 사건이 일어나지 않았다는 가정에 초점을 더 맞추는 경우가 많기에, 이러한 가정에 이름도 붙여놓았는데, 그것이 바로 “귀무가설”이다.

- 귀무가설은 아무일도 일어나지 않았음을 가정하는 가설

- 1종 오류의 정의는 “귀무가설이 참인데 잘못 판단해 기각 해버리는 오류”

- 귀무가설이 참이라는 말은 아무 일도 일어나지 않았음을 의미(False Alarm
), 즉 실제로는 일(화재)이 일어나지 않았는데도 기각(즉, 화재 경보 알람이 울리는 것) 해버린 것

- 2종 오류의 정의는 “귀무가설을 거짓인데도 기각하지 않아서 생기는 오류”

- 귀무가설이 거짓이라는 말은 어떤 일이 실제로 발생했음을 의미(Miss
), 즉 실제로 일어난 일(화재)임에도 기각(즉, 화재 경보 알람이 울리는 것)할 타이밍을 놓친 것

- p-value는 “귀무가설이 맞다고 했을 때, 귀무가설이 말이 될 확률”을 의미하기 때문에  p-value는 1종 오류를 범할 확률과 같은 의미를 갖음

## 모수적 모델, 비모수적 모델
- 모수적 모델은 알려진 확률분포를 기반으로 해당 파라미터를 추정하는 과정이 포함되어 있는 모델(예를 들어 선형 모델을 모델 구축 시에 정규 분포를 가정하기 때문에 모수적 방법론임)

- 비모수적 모델은 확률 분포를 가정하지 않고, 하이퍼파라미터를 이용해 값을 추정하는 모델

- 위 두가지 관점에서 보면 DNN은 파라미터와 하이퍼파리미터 두 개를 모두 가지고 있기 때문에, 모수적과 비모수적 모델의 특징을 모두 가진다고 볼 수 있음(그런데 딥러닝이 특정 확률 분포를 가정하고 모델을 학습시키는 것은 아님)

- 모수적 모델과 비모수적 모델은 데이터의 양이나 분포에 의존하지 않고 일정 개수의 모수로 모델이 표현되는가로 구분할 수도 있음(딥러닝과 선형회귀 같은 모델은 데이터의 양이나 분포에 의존하나, k-NN과 의사결정 나무는 데이터의 양이나 분포에 의존하지 않고 단순히 하이퍼파라미터에 의존함) 

## 빈도주의 통계와 베이지안 통계
- 빈도 주의에서 확률은 철저히 객관적인 실험에 의해서 계산된 값을 의미함, 즉 실제 사건을 기반으로 확률을 계산함(확률을 그 값 자체로 보는 것)

- 베이지안은 확률을 사건 발생에 대한 믿음 또는 척도로 바라보는 관점을 의미함, 따라서 실제 발생하지 않은 사건이라도 주변 요인에 대한 확률, 즉 사전 확률만 있다면 다른 사건이 발생할 확률을 계산할 수 있음(확률을 주장에 대한 신뢰도로 보는 것)

- 즉 전국 대학생의 평균 연령을 23살이라고 한다며, 빈도주의 관점에서는 실험을 더이상 하지 않는다면 그 값은 변하지 않음

- 반대로 베이지안에서는 전국 대학생의 평균 연령이 23살일 확률이 높겠지만, 아닐 확률도 존재 한다고 말하며, 그 확률 분포에 대해서 설명함, 이처럼 베이지안 관점은 우리가 구하고자 하는 값을 정확히 구하지 않고, 어떤 값일 확률이 어느 정도인지에 대한 확률 분포로 대답함

- 일반적으로 사용하는 Deep Learning은 빈도주의 관점임, 왜냐하면 Model의 Parameter들이 하나의 값으로 정해져 있고, 그에 따라 output도 하나의 값으로 출력하기 때문에

- 정답 뿐만 아니라 정답이 어느 값일 확률이 높은지에 대한 distribution을 출력하게 된다면 이는 베이지안 관점의 Deep Learning임

## 베이즈 정리
- 베이즈 정리는 새로운 정보를 토대로 어떤 사건이 발생했다는 주장에 대한 신뢰도를 갱신해 나가는 방법

- 베이지안 관점의 통계학에서는 사전 확률과 같이 이론에 기반한 선험적인, 혹은 불확실성을 내포하는 수치를 기반으로 하고, 거기에 추가 정보(우도)를 바탕으로 사후확률을 갱신(귀납적 추론 방법)

- 관찰을 통해서 예측하고자 하는 클래스가 주어졌을 때 변수가 발생할 분포인 Likelihood를 구하고(Likelihood 만을 사용하여 클래스를 분류하기 위해서는 예측하고자 하는 클래스가 똑같은 비율로 존재한다는 가정이 필요함), 클래스의 비율에 대한 정보인 사전 확률을 서로 곱하고(클래스가 똑같은 비율로 존재하지 않기 때문에 무엇이 더 희귀한지에 대한 정보가 반영되어 있는 사전 지식임), 구한 사전 확률과 Likelihood를 이용하여 Evidence를 계산하고 이를 분모 취한다. 이렇게 값을 구하게 되면 우리는 해당 변수가 주어졌을때 해당 클래스일 확률인 사후 확률을 알 수 있게 된다. 이 사후 확률을 바탕으로 현재 주어진 위치에서 제일 높은 확률 값을 가진 클래스로 우리는 예측을 하게 된다.

- 변수들에 대한 Likelihood를 어떻게 계산하느냐에 따라서 pure Bayesian, naive Bayesian, semi-naive Bayesian으로 구분됨

- naive Bayesian 방식은 사람의 키, 머리크기, 허리둘레가 서로 상관관계가 없는 독립변수라는 가정하에 키의 확률분포, 머리크기의 확률분포, 허리둘레의 확률분포를 각각 구한 후 각각의 확률을 서로 곱하여 최종 결합확률을 계산하는 방식

- pure Bayesian 방식은 사람이 가질 수 있는 모든 (키,머리크기,허리둘레) 조합에 대하여 확률분포를 계산하는 방식(naive Bayesian은 각 변수마다 확률을 계산했다면, pure Bayesian은 변수의 조합 즉 3차원으로 확률을 계산함)

- naive Bayesian 방식은 feature간의 상관관계(키와 머리크기가 가지는 상관관계)를 무시하고 확률을 계산함(이래서 딥러닝에서 다중공선성을 중요하게 여기는 것이군...)

- 만약에 feature간의 상관관계가 없다면 naive Bayesian 방식으로 구한 확률 값도 맞는 값이 될 것이지만, 그렇지 않다면 pure Bayesian 방식으로 계산한 확률 값이 맞음, 그런데 pure Bayesian 방식은 계산하기 까다롭기 때문에 오차를 감수하더라도 naive Bayesian 방식으로 확률을 계산함

- semi-naive Bayesian은 feature들을 먼저 소그룹으로 그룹핑(grouping)을 한 후에 각 그룹 내에서는 feature들 간의 상관관계를 풀(full)로 계산하되, 그룹과 그룹 사이에서는 상관관계가 없는 것으로 확률을 계산하는 방식(만일 feature들을 실제 상관관계가 있는 것끼리 잘 그룹핑할 수만 있다면 semi-naive Bayesian 방식이 가장 효율적인 확률모델이 될 것)

## Maximum Likelihood Estimation(MLE)와 Maximum A Posterior(MAP)
- MLE는 Likelihood 함수의 최대값을 찾는 방범임

- MLE를 가우시안 분포로 가정하고 풀면 MSE와 동치

- MLE를 베르누이 분포로 가정하고 풀면 CE와 동치

- Likelihood는 지금 얻은 데이터가 이 분포로부터 나왔을 가능도를 말함, 즉 Likelihood 함수는 각 데이터 샘플에서 현재 추정하고자 하는 분포에서 나올 가능도를 계산하여 이들을 모두 곱한 것임

- 관찰을 통해서도 Likelihood를 계산할 수 있지만, Likelihood 함수를 단순히 정해지지 않은 몇 개의 parameter로 이루어진 함수로 모델링을 한 후에, 이 모델이 주어진 Data를 가장 잘 설명하도록 parameter들을 구해내며, Likelihood 함수의 최대값을 찾을 수 있고, 이러한 방법이 바로 딥러닝임

- MLE를 사용하여 우리는 주어진 데이터를 가지고 Likelihood 함수를 최대값으로 만들 수 있는 파라미터를 얻고자 모델의 가중치를 업데이트 해나가며, 최적의 가중치를 찾아나감

- 일반적인 딥러닝에서 MLE의 Likelihood 함수는 가중치를 모르기 때문에, 가중치에 대한 함수값으로 표현이 됨

- 사후확률은 데이터가 주어졌을 때의 가중치의 분포, 사전확률은 가중치에 대한 확률 값, Likelihood 함수는 가중치가 주어졌을 때의 데이터의 분포 값

- 각 샘플들의 Likelihood 값은 서로 독립적이기 때문에 Likelihood를 계산할 때 서로 곱하게됨, 그런데 곱하면 값이 너무 커지기 때문에 우리는 log를 취해줌으로써 덧셈으로 변경함

- Deep Learning 등에서 L2 Loss를 이용한다는 것은 주어진 Data로부터 얻은 Likelihood를 최대화시키겠다는 뜻으로 해석할 수 있음, 즉 L2 Loss를 최소화 시키는 일은 Likelihood를 최대화 시키는 일인 것

- MAP는 사후확률은 최대화 시키는 방법임

- 우리는 사후확률을 계산할 때 Likelihood와 사전 확률은 같이 사용함, 즉 MAP는 Likelihood와 사전 확률은 같이 사용하여 사후확률은 최대화함

- 딥러닝에서 MAP를 사용하는 것은 사전 확률이 결국 파라미터에 대한 확률값을 의미하기 때문에 Weight Decay(Regularization)라는 방식으로 사용됨

- L2 Regularization을 쓴다는 것은 주어진 Data를 적용함과 동시에 w에 Gaussian Distribution이라는 Prior를 걸어 주어 MAP를 통해 w를 구하겠다는 것으로 해석할 수 있음

- L1 Regularization을 쓴다는 것은 주어진 Data를 적용함과 동시에 w에 Laplacian Distribution이라는 Prior를 걸어 주어 MAP를 통해 w를 구하겠다는 것으로 해석할 수 있음

- 구하고자 하는 대상을 철저히 데이터만을 이용해서 구하고 싶다면 MLE를 이용하는 것

- 데이터와 더불어 우리가 갖고 있는 사전 지식까지 반영하고 싶다면 MAP를 이용하는 것(사전 지식에 어떻게 보면 output에 대한 특정 제약 조건이라고 볼 수 있음)

- 어떤 함수의 최대값을 찾는 방법 중 가장 보편적인 방법은 미분계수를 이용하는 것이고, 우리는 MAE, MAP의 식을 경사하강법을 이용하여 최대가 되는 가중치(모수)를 찾을 수 있음

## Entorpy와 정보 이론
- 정보 이론에서 정보는 특정한 관찰에 의해 얼마 만큼의 정보를 흭득했는지 수치로 정량화한 값을 의미함 

- 따라서 놀랄만한 내용일 수록, 발생할 확률이 낮은 사건 일 수록 정보량이 많다고 함. 왜냐하면 직관적으로 생각해보더라도 매번 나오는 정보보다 어쩌다 한번 우리에게 주어진 정보가 그 가치가 더 크며, 이는 우리에게 더 큰 정보를 줄 수 있다고 볼 수 있음

- 통계학에서는 엔트로피를 평균 정보량(정보량의 기댓값, 해당 사건이 발생할 확률과 사건을 곱하고 그 값을 모두 합친 값), 즉 정보의 불확실성이라고 표현함

- 따라서 엔트로피가 크다는 것은 정보의 불확실성이 크다는 것을 의미하고 이는 특정 사건이 발생할 확률이 고르다고 표현할 수 있음. 왜냐하면 사건들의 발생할 확률이 고르다면 그 만큼 우리가 원하는 정답을 얻기 위해 많은 관찰을(모든 사건을 여러번 확인해봐야함) 해야하기 때문임

- 반대로 엔트로피가 작다는 것은 정보의 불확실설이 작다는 것을 의미하고 이는 특정 사건이 발생할 확률이 고르지 않다고 표현할 수 있음(발생할 확률이 매우 낮은 사건이 존재하거나 발생활 확률이 매우 높은 사건이 존재함). 왜냐하면 특정 사건이 발생할 확률이 높다면 우리는 그 사건을 제외하고 새로운 사건을 탐색할 수 있기 때문임

- 즉, 정보의 불확실성이 낮다는 것은 탐색하려는 사건들이 발생할 확률이 고르지 않다는 것을 의미하고, 정보의 불확실성이 크다는 것은 탐색하려는 사건들이 발생할 확률이 고르다는 것을 의미함(이산확률변수일 때는 균일 분포일때, 연속확률변수일 때는 정규 분포일 때)

- 정보의 불확실성이 낮음 -> 발생할 확률이 매우 높거나 낮은 사건들이 존재함 -> 발생할 확률이 낮은 사건을 통해서 많은 양의 정보를 얻을 수 있음(무엇이 중요한 사건인지 알기 수월함)

- 정보의 불확실성이 높음 -> 발생할 확률이 서로 엇비슷한 사건들이 많이 존재함 -> 모든 사건으로 부터 얻을 수 있는 정보량이 비슷함(무엇이 중요한 사건인지 알기 어려움)

## Cross Entropy
- 크로스 엔트로피는 한마디로 하면 예측과 달라서 생기는 정보량이라고 할 수 있음
- 크로스 엔트로피는 타겟값과 모델의 출력값이 얼마나 다른지 알려주는 식이며, Target을 정확하게 맞추면 크로스 엔트로피의 값은 낮아짐(이상적인 정보에 점차 다가가고 있음)

## KL-Divergence
- 두 확률 분포간의 차이를 계산하는 방법
- 두 확률 분포를 A와 B라고 한다면 A를 기준으로 볼 때의 B에 대한 크로스 엔트로피를 구하고, A에 대한 크로스 엔트로피를 구해서, 두 값 간의 차이를 계산함.
- 두 값의 차이가 만약 0에 가까워 진다면 두 확률 분포 간의 차이가 없다는 것을 의미함

## 참고 자료
- https://angeloyeo.github.io/
- https://hyeongminlee.github.io/
- https://darkpgmr.tistory.com/
- https://brunch.co.kr/@seoungbumkim/7
- https://icim.nims.re.kr/post/easyMath