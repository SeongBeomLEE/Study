# 확률과 통계
## 통계학이란
- 통계학이란 한마디로 표현하면, 모집단의 특성을 잘 대표하는 표본을 뽑아서 그 표본에 있는 제한된 정보를 이용하여 미지의 값인 모집단의 특성인 모수들에 대하여 통계적 추론을 하고자 하는 학문임

## 평균과 중앙값
- 평균은 모든 데이터를 다 더해서 데이터의 수로 나눈 값을 의미함
- 중앙값은 모든 데이터를 크기 순으로 나열하여 정확히 50%에 위치하는 값을 의미함
- 따라서 평균은 이상치에 민감하지만, 중앙값은 평균보다 덜 민감함

## 심슨의 역설
- 부분에서 성립하던 성질이 전체에서는 성립하지 않는 것을 심슨의 역설이라고 함
- 예를 들어 남자:9 여자:1의 비율을 가지는 지역이 있다고 했을 때, 이 지역을 성별을 나누지 않고 분석하면 남자의 특성을 가진다고 해석할 수 있음, 하지만 성별을 나누어 분석하면 각 성별마다의 특성이 존재한다는 것을 확인할 수 있을 것임
- 이처럼 부분에서 성립하던 성질이 전체에서는 성립하지 않을 수도 있기 때문에 분석시에는 부분적으로 나눠서 분석을 하는 것이 중요함

## 상관 관계와 인과 관계
- 상관 관계는 원인과 결과에 상관 없이 특정 변수가 변할 때 다른 변수도 함께 변하면 두 변수는 서로 상관 관계에 있다고 함(A 상승or하락 - B 상승or하락 <- 양의 상관 관계 / A 상승or하락 - B 하락or상승 <- 음의 상관 관계)
- 인과 관계는 상관 관계를 지니는 두 변수에 시간적 우선 순위가 존재하여 원인과 결과로 설명할 수 있을 때 두 변수는 인과 관계를 가진다고 함(상관 관계는 인과 관계의 필요 조건 중 하나임)
- 결국 인과 관계를 파악하는 데에는 도메인 지식이 많이 필요함
- 또한 상관 관계는 선형 관계만을 표현할 수 있음
- 이에 X**2과 같은 형태로 표현되는 비선형 관계는 실제로는 서로 관련이 있지만 상관 계수로는 서로 관련이 없는 것처럼 계산될 수 있음
- 따라서 상관 계수를 무조건 믿으면 안되고 시각화를 이용해 변수간의 관게를 판단하는 것이 중요함

## 선험적 확률과 경험적 확률
- 선험적 확률(수학적 확률)은 각 사건이 발생하는 확률이 같다는 것으로, 시행에 대해서 일어날 수 있는 모든 경우의 수가 N가지이고, 어떤 사건이 일어나는 경우의 수가 K가지일 떼, 어떤 사건이 일어나는 확률이 K/N인 것을 뜻함, 즉 경험하지 않고도 이론적으로 미리 알 수 있는 확률을 의미함(주사위 같은)

- 경험적 확률은 같은 시행을 여러 번 반복하여 얻을 수 있는 횟수를 통해 나오는 확률을 의미함, 즉 시물레이션이나 실험을 통해서 나오는 확률임, 이런 확률이 필요한 이유는 모든 사건을 수학적 확률로 계산할 수 없기 때문임(화산이 폭발할 확률을 우리가 수학적으로 계산할 수 없음, 그러나 시물레이션을 통해서 확률을 계산할 수는 있을 것임)

## 기댓값, 분산, 공분산, 상관계수, 공분산 행렬
- 기댓값은 확률적 사건에 대한 평균 값으로, 사건이 일어나서 얻는 값과 그 사건이 일어날 확률을 곱한 것을 모든 사건에 대해 합한 값으로, 어떤 확률적 사건에 대한 평균의 의미를 갖음

- 분산은 데이터가 평균으로 부터 얼마나 퍼져있는지를 가늠할 수 있는 값으로, 데이터의 분포를 알 수 있음

- 분산은 우리가 한 예측이 얼마나 불확실한지의 정도의 표현으로도 사용 가능함, 왜냐하면 분산이 작다는 것은 분포의 폭이 작다는 것이고 분산이 크다는 것은 분포의 폭이 넓다는 것임, 분포의 폭이 넓을 수록 우리가 예측하고자 하는 값의 불확실성은 높아진다고 볼 수 있음(정답이 평균이라고 했을 때 평균이 아닌 다른 값이 선택될 확률이 높아지기 때문에)

- 공분산은 두 변수 간의 상관 관계를 파악하는데 쓰이는 개념으로, 각 변수의 편차를 서로 곱한 것의 평균임

- 그런데 공분산 자체가 X와 Y의 단위의 크기에 영향을 받기 때문에, 이를 보완하고자 공분산을 표준편차로 니누어 표준화 한 것이 상관 계수임

- 공분산 행렬은 여러 개의 변수가 서로 어떤 관계를 가지는지 나타내고자, 공분산을 행렬로 구한 것이 바로 공분산 행렬임(대각 행렬은 분산, 나머지 부분은 각 변수 간의 공분산 값임)

## 확률 변수, 확률 분포, 확률 밀도 함수, 누적 분포 함수, 확률 질량 함수, 누적 질량 함수
- 확률 변수는 특정 확률로 발생하는 각각의 결과(확률값)를 수치적 값으로 표현한 변수(실수값)를 의미함, 따라서 어떻게 보면 확률 변수는 결과 값을 하나의 실수값으로 변환해주기 때문에 함수 식이라고 표현할 수도 있음

- 각 확률 변수의 값들은 발생할 확률 값들이 가지고 있으며, 이 확률 변수가 가지는 확률값을 분포로 표현한 것이 확률 분포임, 즉 획률 분포는 샘플(관측치)들이 가질 수 있는 수치 값을 각각 0과 1 사이의 확률로 표현할 때, 이 확률 값들의 패턴이라고 볼 수 있음

- 확률 변수를 특정한 확률 값으로 표현하는데 사용되는 식이 확률 함수라고 볼 수 있음

- 모든 사건 -실험-> 확률 변수(동일한 사건은 같은 확률 변수를 가짐(앞뒷, 뒷앞)) -> 확률 함수(확률 변수가 발생할 확률을 표현하는 식) -> 확률 분포(확률의 분포)

- 모든 확률 분포는 한 개 이상의 모수를 가지고 있으며(평균, 분산 등), 이는 확률 분포의 모양을 결정함(정규 분포의 경우 평균과 분산 2개의 모수가 있고 이들이 정규 분포의 모양을 결정), 많은 경우 분포의 모수는 알려져 있지 않으며 모수를 추측해보는 과정을 통계학에서 추정이라고 함

- 확률 밀도 함수(PDF)는 연속 확률 변수의 분포(확률)를 나타내는 함수

- 누적 분포 함수(CDF)는 연속형 분포의 주어진 확률 변수가 특정 값보다 작거나 같은 확률을 나타내는 함수

- 확률 질량 함수(PMF)는 이산 확률 변수의 분포(확률)를 나타내는 함수

- 누적 질량 함수(CMF)는 이산형 분포의 주어진 확률 변수가 특정 값보다 작거나 같은 확률을 나타내는 함수

## 이항 분포
- 이항 분포는 동전 던지기의 앞면 혹은 뒷면과 같이 두 가지 사건만 일어날 수 있는 경우에 대해 기대해 볼 수 있는 분포

- 이항 분포는 특정 조건을 만족할 때 분포의 모양이 정규 분포에 근사해짐

- 이항 분포는 연속된 n번 독립적 시행에서 각 시행이 확률 p를 가질 때의 이산 확률 분포

- 이항분포의 확률질량함수의 식은 아래와 같음, 식의 의미는 성공 확률 p를 갖는 이벤트를 n번의 시행 했는데, 그 중 성공한 횟수는 k번 이라는 것임, 그러면 자연스럽게 1-p의 시행 횟수는 n-k가 됨

- $\binom n k p^k(1-p)^{n-k}$

- 이항분포는 p라는 획률을 가지는 사건을 연속 n회 시행했을 때, 0~n회 사이의 시행 중 우리가 원하는 사건이 몇번 발생할 지를 확률적으로 기술해놓은 분포라고 할 수 있음

- 총 시행 횟수가 n, 성공 확률이 p인 이항 분포의 평균 값은 np, 분산은 np(1-p)

- 수학자들은 이항 분포가 정규분포의 형태와 유사해질수 있다고 볼 수 있는 기준을 np와 $\sqrt{np(1-p)}$가 5보다 클때로 보며, 이때 평균이 np이고 분산이 np(1-p)인 정규분포를 따른다고 함

## 기하 분포
- 기하 분포는 성공 혹은 실패의 두 가지 경우의 수로 구성된 시행을 연달아 수행 시 처음 성공할 때 까지 시도한 횟수 k에 대한 분포(성공할 확률이 높은 시행은 k가 낮은 값일 때 더 큰 값을 가질 것임)

- 성공 확률이 p인 시행에 대해 k번 시행 후 첫번째 성공을 얻을 확률은 다음과 같으며, 식을 보면 (1-p)를 매 항마다 계속해서 곱해나간다는 것을 알 수 있음(계속 틀렸으니깐 당연한거임)

- $(1-p)^{k-1}p$

- 기하 분포에서 보여주는 것은 성공 확률이 p일 때 k번째 처음으로 성공할 수 있는 확률을 의미함
    
- 분포의 모양을 바탕으로 현재 내가 하고 있는 일이 언제 쯤에 성공할 지 대략적인 감을 알 수 있음, 즉 성공 확률이 높은 행동일 수록 초기에 매우 큰 값을 가지고, 그 뒤에 제일 처음으로 성공할 확률이 낮아지지 점점 급감할 것임, 반대로 성공 확률이 낮은 행동은 언제 성공할지 누구도 모르니 전체적으로 평탄한 모양을 기질 것임

- 합격 확률이 0.2인 시험이 있을 때, 이 시험을 3번째 만에 합격할 확률은?
    - 0.2 + (0.8)^1*0.2 + (0.8)^2*0.2 = 0.448
    - 1, 2, 3번째에 성공할 확률들을 다 구해서 더하면 됨


## 포아송 분포
- 이항분포에서 n이 너무 크고 p가 너무 작은 경우에 이항 분포의 확률분포를 근사적으로 계산하기 위해서는 극한값을 이용한 새로운 형태의 분포를 제시하는 것이 바람직하고, 이 새로운 형태의 분포가 바로 포아송 분포

- 포아송 분포는 수 많은 사건 중(n->무한) 특정한 사건이 발생할 확률이 매우 적은(즉, p -> 0)확률 변수가 갖는 분포

- 정해진 시간 안에 어떤 사건이 일어날 횟수에 대한 기댓값을 $\lambda$ 라고 했을 때, 그 사건이 n회 일어날 확률은 다음과 같음

- $f(n;\lambda) = \frac{\lambda^n e^{-\lambda}}{n!}$

## 지수 분포
- 사건이 서로 독립적일 때, 일정 시간동안 발생하는 사건의 횟수가 포아송 분포를 따른다면, 다음 사건이 일어날 때 까지의 대기 시간은 지수 분포를 따름

- 포아송 분포는 단위 시간동안 어떤 사건이 평균적으로 $\lambda$ 회 발생한다고 했을 때, 단위시간동안 사건이 k번 일어날 확률에 대한 분포를 지칭

- 그러면 여기서 다음 사건이 처음 일어나는 때 까지 걸리는 시간에 대한 분포를 구할 때는 지수 분포를 사용

## 정규 분포
- 어떤 값을 중심으로 대칭적으로 분포하며 중심에서 멀어질수록 도수가 작아지는 종 모양의 분포

## 중심극한정리
- 모집단의 분포의 모양에 상관 없이 표본 평균의 평균은 정규 분포를 따른다는 정의로 해당 정의를 이용해 모집단의 모수인 평균을 통계적으로 추론할 수 있고, 모집단의 평균을 알면 모집단의 특성을 추론할 수 있기 때문에 중요한 정의임

- 여기서 또 신기한 점은 표본을 추출하는 모집단이 서로 독립적이라면, 여러개의 서로 다른 모집단에서 표본을 뽑더라도 표본 평균의 평균은 정균 분포를 따르게 됩니다. (랴푸노프 중심극한정리)

- 그리고 대체적으로 표본을 비교할 때 평균을 많이 사용하기 때문에, 중심극한정리를 염구해두고 만든 많은 이론들이 있어서 중요한 정의임

## 카이제곱분포
- 표준정균분포를 따르는 확률 변수들을 k개 샘플링하고, 그 값들을 제곱합하여 히스트그램으로 나타낸 분포(회귀에서도 에러 값을 제곱하하여 에러를 표현함)

- 카이제곱분포 또한 중심극한정리에 의해서 k의 수가 커지면 정균분포를 따르게 됨

- 카이제곱 분포는 오차(error) 혹은 편차(deviation)를 분석할 때 도움을 받을 수 있는 분포이기 때문에 사용됨

- 여기서 중요한 점은 우리가 보통 error를 정규분포로 설계한다는 점을 이해해야함(회귀 분석의 가정인 정규성)

- 적합도 검정은 독립변수가 하나이고 이론적으로 기대되는 빈도의 분포(frequency distribution)와 관찰한 빈도의 분포를 비교하기 위해 사용

- 교차 분석은 범주형 변수가 여러 개인 경우에 적용하는 분석 방법, 교차 분석의 목적은 여러 범주형 변수의 범주 간 차이가 기댓값에서 유의하게 벗어나는지 확인하는 것

## 모집단, 모수, 표본, 표준 오차
- 모집단은 정보를 얻고자 하는 관심 대상의 전체 집합을 의미

- 모수는 모집단의 특성을 의미, 우리는 전체 집단의 모든 데이터를 알지 못한더라도 수학적으로 그 분포를 기술할 수 있는 특성값을 알 수만 있다면, 비슷하게 모집단의 특성을 통계적으로 확인할 수 있는데, 여기서 특성치들을 우리는 모수라고하며, 모집단의 특성을 나타내는 모수를 파악하여 모집단의 특성을 파악하고자하는 것이 목표

- 표본이란 모집단의 부분집합을 의미

- 표본을 추출하는 이유는, 우리가 모집단 전체에 대해 검사하기에는 비용이 너무 많이 들기 때문임(현실적으로 모집단을 모두 조사하는 것은 불가능함)

- 표본은 매번 추출할 때 마다 그 값이 달라지는 특성을 가지며, 표본으로부터 그 분포의 특성을 나타내는 표본 통계량을 만들 수 있고, 표본 통계량은 모수의 추정치로 볼 수 있으며, 이 값은 항상 오차를 수반함

- 표준 오차란 표본 통계량의 표준 편차를 의미함(여러 개의 표본을 얻어서 거기서 표본 통계량을 얻으면, 그 표본 통계량 값들의 표준 편차를 구할 수 있고, 그 값을 표준 오차라고 함)

- 표준 편차는 모집단의 분포가 얼마나 퍼져있는가를 서술하는 개념이고, 표준 오차는 표본 통계량(추정치)의 평균 값들에 대한 불확실도를 수치화한 개념

## 검정 통계량
- 검정 통계량은 통계적 가설의 진위 여부를 검정하기 위해 표본으로 부터 계산하는 통계량

- 즉, 검정 통계량은 표본 통계량을 2차 가공한 형태로 생각하면 편함, 통계적 가설 진위 여부를 검정한다는 것은 검정통게량의 값이 기준을 벗어나는지 확인하여 세워둔 가설이 틀렸다고 할 수 있는지 확인하는 과정임

## t-value
- 우리가 두 표본 집단간의 평균 차이를 비교한다고 할 때, 우리가 비교하고자하는 평균 값은 표본 평균이기 때문에 오차를 염두해두고 두 표본 간의 차이에 관한 지표를 만들어야 함

- 우리는 표돈 통계량의 불확실성에 대한 값이 표준 오차라는 것을 알고 있음. 

- 따라서 t-value는 표본 평균과 표준 오차(불확실성)를 가지고 계산할 수 있음

- 두 표본 그룹 간의 평균 차이 / 두 그룹간 평균 차이에 대한 불확실도로 t-value를 계산할 수 있으며, 두 그룹간 평균 차이에 대한 불확실도는 각 표본의 분산 값을 각 표본의 개수 n으로 나누어 합한 후 루트를 취한 값으로 계산됨

- t-value는 각 표본의 평균 값의 차이를 표준오차로 나눠준 값으로 정의함

- t-value들의 분포를 계산하여 공식화 한 것이 t-분포라고 할 수 있음

- t-분포를 사용하여 두 표본 간의 차이가 통계적으로 유의미한지를 알 수 있음

## F-value
- F-value는 여러 표본 집단을 비교하기 위한 지표이며, t-value와 마찬가지로 그룹 간의 차이 / 불확실도로 계산할 수 있음, 근데 t-value와 달리 계산 시에 분산을 사용함

- t-value를 제곱한 값이 결국엔 F-value임

- F-value들의 분포를 계산하여 공식화 한 것이 F-분포라고 할 수 있음

## 귀무가설과 대립가설
- 귀무가설은 "새로울 게 없다는 가설"

- 대립가설은 "새로운 것이 있다는 가설"

- 실험을 통해서 새로운 사실을 발견했다는 사실을 입증하기 위해서 귀무가설을 사용하는 이유
    - 참이 아님을 증명하는 것이 참임을 증명하는 것보다 휠씬 쉽기 때문에
    - 귀무가설을 "올바르게" 서술하는 것이 대립가설을 "정확하게" 서술하는 것보다 실패할 가능성이 적음
    - 우리는 모수에 대해서 알 수 없으며, 연구에 있어 주관성이 개입되어선 안되기 때문에

- 위와 같은 이유로 귀무가설을 검증하는데 실패함으로써 간접적으로 새로운 가설, 즉 대립가설에 대해 확인하고자 하는 것임

- 즉, 실험에 어떤 변화가 있다는 사실을 검증하고자 한다면 역으로 가설이 없다고 가정한 뒤에 실험을 진행하는 것임(귀무 가설 설정)

- 변화가 없다는 가설(귀무가설)에 모순이 있다는 것을 발견하게 되면 이것을 근거로 변화가 있다는 사실(대립가설)을 간접적으로 증명할 수 있게 되는 것임

- 귀무가설을 이용한 검증 방법은 무죄 추정의 원칙으로 설명할 수 있음, 무죄 추정 원칙을 따르면 용의자나 피고인은 유죄로 판결이 확정(귀무가설이 기각된 상태)되기 전 까지는 무죄로 추정(귀무가설이 기각되지 않은 상태)하고, 유죄로 판결하기 위해선 피고인이 실제로 무죄라고 가정했을 때 발생할 수 없는 증거나 상황(통계학적으로 유의한 수준)이 뒷받침 되어야 함

- 귀무가설 검증 과정은 오로지 검증 실패에만 주안점을 두는 과정이기 때문에, 귀무가설을 기각할 수 있게 되었다고 해서 대립가설을 증명한 것은 아니라는 점이 중요함

- 대립가설을 간접적으로 이용한 통계적 추론 방법이 신뢰 구간을 이용한 검정 방법

- 대립가설을 직접적으로 이용한 통계적 추론 방법이 베이즈 추론 방법

## p-value
- p-value는 확률값으로써 귀무가설과 현재 얻은 결과가 얼마나 일치(compatible)하는지를 말해주는 값임

- p-value는 검정 통계량에 관한 확률인데, 우리가 얻은 검정 통계량보다 크거나 같은 값을 얻을 수 있을 확률을 의미함(즉 p-value가 0.05 보다 작다는 것은 귀무 가설이 틀릴 확률이 높다는 것을 의미함, 왜냐하면 p-value는 확률 값이니깐 낮은 값이 나오면 현재 값이 나올 확률 자체가 낮다는 것을 의마하고, 이는 귀무 가설이 틀렸다는 것을 의미함)

- 우리가 계산하는 검정 통계량들은 거의 대부분이 귀무가설을 가정하고 얻게 되는 값임

- 두 표본 평균의 차이를 검증한다고 할 때, 두 표본 집단의 모집단은 같다는 가정을 전제함

- "우리가 얻은 데이터에 있는 두 표본 집단이 같은 모집단에서부터 나온거라고 치자, 그랬을 때, 우리가 이런 검정 통계량(가령, t-value)을 얻었는데 이게 얼마나 말이되는거냐?" 이에 대한 해답이 바로 p-value임(따라서 값이 낮다는 것은 말이 될 확률이 낮다는 것을 의미함)

- 표본 통계량(표본 집단의 특성) -가공-> 검정 통계량(표본 통계량을 가지고 통계적 가설의 진위 여부를 판단하기 위한 값, t-value / F-value 등) -가공-> p-value(검정 통계량에 관한 확률, 검정 통계량이 유의미한지 판단하기 위한 값)

- p-value는 효과의 크기(effect size)와 표본의 크기(n 수)의 정보를 한꺼번에 담고 있음(검정 통계량을 압축한 정보)

- 효과의 크기가 커지거나 표본의 크기가 커지거나 둘 중 하나만 변하더라도 p-value는 마치 유의한 차이를 담보할수 있을 것 마냥 작아짐, 즉 실제로 한 모집단에서 두 표본 집단이 나왔음에도 효과의 크기나 표본의 크기가 너무 커서 p-value는 0.05보다 낮을 수 있으며 귀무가설이 기각되어 대립 가설이 채택됨에도 불구하고 대립 가설이 참이 아닐 수도 있음

- 낮은 p-value (통상 0.05 이하)를 얻었다는 것은 귀무 가설과 현재의 실험 결과가 그만큼 일치하지 않는다는 것을 말하는 것이고, 이에 따라 귀무 가설을 기각함

- 귀무가설을 기각할 수 있다는 것은 귀무가설과 현재 얻은 결과가 서로 양립할 수 없음을 의미하며, 우리는 양립할 수 있는 정도를 표현하기 위해서 p-value를 사용 (p-value가 높다는 것은 두 값은 서로 양립할 수 있음, 낮다는 것은 양립할 수 있는 가능성이 낮다는 것)

## 신뢰 구간
- 표본 통계량에는 항상 불확실성은 수반하기 때문에(샘플링), 그나마 내가 확실히 말할 수 있는 정도를 구간으로 표현하며, 이를 신뢰 구간이라고 부르고, 우리는 이를 이용해 통계적 추정을 함

- 즉, 내가 지금 추출한 표본 평균은 모평균으로부터 2 * 표준 오차(SEM, 표본 평균의 표준 편차) 범위 안에 95% 확률로 들어온다라고 설명하는 것

- 여기서 95% 라는 의미는 100번 정도 샘플링을 했을 때, 우리가 표본 평균을 바탕으로 모평균을 추론했을 때, 그 값이 95번 정도는 해당 신뢰 구간안에 들어온다는 의미임

- 여기서 95% 는 신뢰 수준

- 2 * 표준 오차(SEM, 표본 평균의 표준 편차) 범위는 신뢰 구간

- p-value는 효과의 크기가 커지거나 표본의 크기가 커지거나 둘 중 하나만 변하더라도 그 값이 매우 작아질 수 있음, 이에 효과의 크기(effect size)를 함께 보여주는 신뢰 구간을 함께 사용하면 p-value를 단점을 개선할 수 있음(가령 두 값의 범위가 매우 작다면 아무리 p-value의 값이 낮더라도 실제로는 유의미한 차이를 낸다고 볼 수는 없을 것임, 이처럼 두 값을 함께 사용하면 더 많은 정보를 확인할 수 있음)

## 1종 오류와 2종 오류
- 1종 오류는 귀무가설이 참인데 잘못 기각할 때 발생하는 오류

- 2종 오류는 귀무가설이 거짓인데 기각하지 않았을 때 발생하는 오류

- 검정은 확률을 기반으로 하기 때문에 어떤 가설 검정도 100% 확실한 것은 없음, 이에 언제나 잘못된 결론을 내릴 가능성이 있음

- 우리가 사건에 대해 다루는 가설은 딱 두가지이다. 이 사건이 일어났거나, 일어나지 않았거나.

- 통계학이 사건이 일어나지 않았다는 가정에 초점을 더 맞추는 경우가 많기에, 이러한 가정에 이름도 붙여놓았는데, 그것이 바로 “귀무가설”이다.

- 귀무가설은 아무일도 일어나지 않았음을 가정하는 가설

- 1종 오류의 정의는 “귀무가설이 참인데 잘못 판단해 기각 해버리는 오류”

- 귀무가설이 참이라는 말은 아무 일도 일어나지 않았음을 의미(False Alarm
), 즉 실제로는 일(화재)이 일어나지 않았는데도 기각(즉, 화재 경보 알람이 울리는 것) 해버린 것

- 2종 오류의 정의는 “귀무가설을 거짓인데도 기각하지 않아서 생기는 오류”

- 귀무가설이 거짓이라는 말은 어떤 일이 실제로 발생했음을 의미(Miss
), 즉 실제로 일어난 일(화재)임에도 기각(즉, 화재 경보 알람이 울리는 것)할 타이밍을 놓친 것

- p-value는 “귀무가설이 맞다고 했을 때, 귀무가설이 말이 될 확률”을 의미하기 때문에  p-value는 1종 오류를 범할 확률과 같은 의미를 갖음

## 모수적 모델, 비모수적 모델
- 모수적 모델은 알려진 확률분포를 기반으로 해당 파라미터를 추정하는 과정이 포함되어 있는 모델(예를 들어 선형 모델을 모델 구축 시에 정규 분포를 가정하기 때문에 모수적 방법론임)

- 비모수적 모델은 확률 분포를 가정하지 않고, 하이퍼파라미터를 이용해 값을 추정하는 모델

- 위 두가지 관점에서 보면 DNN은 파라미터와 하이퍼파리미터 두 개를 모두 가지고 있기 때문에, 모수적과 비모수적 모델의 특징을 모두 가진다고 볼 수 있음(그런데 딥러닝이 특정 확률 분포를 가정하고 모델을 학습시키는 것은 아님)

- 모수적 모델과 비모수적 모델은 데이터의 양이나 분포에 의존하지 않고 일정 개수의 모수로 모델이 표현되는가로 구분할 수도 있음(딥러닝과 선형회귀 같은 모델은 데이터의 양이나 분포에 의존하나, k-NN과 의사결정 나무는 데이터의 양이나 분포에 의존하지 않고 단순히 하이퍼파라미터에 의존함) 

## 연역법과 귀납법
- 연역법은 명백히 알려진 사실로 부터 논리를 전개하는 방식
- 귀납법은 다양한 관찰을 통해 얻은 지식을 바탕으로 논리를 전개하는 방식

## 빈도주의 통계와 베이지안 통계
- 빈도주의는 원래의 확률을 알고 있다고 가정하고, 연역적 방법(동일한 환경에서 실험을 반복하여 계산)으로 발생할 결과를 파악한 뒤, 관측 결과와 대조하여 원래의 확률이 맞는지 확인하는 방식 (연역적 접근)

- 베이지안은 원래의 확률을 정확히 알 수 없다고 생각하고, 우리가 어림짐작으로 파악하는 확률을 바탕으로 관측 결과들과 조합하여 원래의 확률을 추정하는 방식 (귀납적 접근)

- 이러한 확률을 확인 하는 방식의 차이에 의하여 베이지안의 경우 발생하지 않은 사건에 대해서도 확률을 계산할 수 있게 됨

- 사전 확률을 정의하고, 데이터에서 여러 사건을 관측하여 우도를 계산하고, 우도와 사전 확률을 바탕으로 사후 확률을 계산하면서 원래의 확률을 추정하게 됨

- 또한 확률을 확인 하는 방식의 차이에 의하여 빈도주의 경우 확률을 객관적인 관점으로 해석하고, 베이지안에서는 확률을 그 사건이 발생할 하나의 신뢰도로 바라보기 때문에 주관적이 관점으로 해석함, 이에 베이지안 관점에서의 확률은 불확실성이 내포되어 있다고 할 수 있음

- AI는 베이지안 처럼 데이터에서 다양한 특징을 관찰하여 패턴을 파악하고, 이를 바탕으로 계속 정보를 업데이트 해나가기 때문에 베이지안 관점과 유사하다고 할 수 있는 것임

- 이에 항상 불확실성을 내포하고 있기 때문에 연역적 방법과 달리 설명력에 한계를 가지는 것임(베이지안으로 추정된 논리가 항상 맞다는 보장을 할 수 없음)

## 베이즈 정리
- 베이즈 정리는 새로운 정보를 토대로 어떤 사건이 발생했다는 주장에 대한 신뢰도를 갱신해 나가는 방법

- 베이지안 관점의 통계학에서는 사전 확률과 같이 이론에 기반한 선험적인, 혹은 불확실성을 내포하는 수치를 기반으로 하고, 거기에 추가 정보(우도)를 바탕으로 사후확률을 갱신(귀납적 추론 방법)

- 관찰을 통해서 예측하고자 하는 클래스가 주어졌을 때 변수가 발생할 분포인 Likelihood를 구하고(Likelihood 만을 사용하여 클래스를 분류하기 위해서는 예측하고자 하는 클래스가 똑같은 비율로 존재한다는 가정이 필요함), 클래스의 비율에 대한 정보인 사전 확률을 서로 곱하고(클래스가 똑같은 비율로 존재하지 않기 때문에 무엇이 더 희귀한지에 대한 정보가 반영되어 있는 사전 지식임), 구한 사전 확률과 Likelihood를 이용하여 Evidence를 계산하고 이를 분모 취한다. 이렇게 값을 구하게 되면 우리는 해당 변수가 주어졌을때 해당 클래스일 확률인 사후 확률을 알 수 있게 된다. 이 사후 확률을 바탕으로 현재 주어진 위치에서 제일 높은 확률 값을 가진 클래스로 우리는 예측을 하게 된다.

- 변수들에 대한 Likelihood를 어떻게 계산하느냐에 따라서 pure Bayesian, naive Bayesian, semi-naive Bayesian으로 구분됨

- naive Bayesian 방식은 사람의 키, 머리크기, 허리둘레가 서로 상관관계가 없는 독립변수라는 가정하에 키의 확률분포, 머리크기의 확률분포, 허리둘레의 확률분포를 각각 구한 후 각각의 확률을 서로 곱하여 최종 결합확률을 계산하는 방식

- pure Bayesian 방식은 사람이 가질 수 있는 모든 (키,머리크기,허리둘레) 조합에 대하여 확률분포를 계산하는 방식(naive Bayesian은 각 변수마다 확률을 계산했다면, pure Bayesian은 변수의 조합 즉 3차원으로 확률을 계산함)

- naive Bayesian 방식은 feature간의 상관관계(키와 머리크기가 가지는 상관관계)를 무시하고 확률을 계산함(이래서 딥러닝에서 다중공선성을 중요하게 여기는 것이군...)

- 만약에 feature간의 상관관계가 없다면 naive Bayesian 방식으로 구한 확률 값도 맞는 값이 될 것이지만, 그렇지 않다면 pure Bayesian 방식으로 계산한 확률 값이 맞음, 그런데 pure Bayesian 방식은 계산하기 까다롭기 때문에 오차를 감수하더라도 naive Bayesian 방식으로 확률을 계산함

- semi-naive Bayesian은 feature들을 먼저 소그룹으로 그룹핑(grouping)을 한 후에 각 그룹 내에서는 feature들 간의 상관관계를 풀(full)로 계산하되, 그룹과 그룹 사이에서는 상관관계가 없는 것으로 확률을 계산하는 방식(만일 feature들을 실제 상관관계가 있는 것끼리 잘 그룹핑할 수만 있다면 semi-naive Bayesian 방식이 가장 효율적인 확률모델이 될 것)

## Maximum Likelihood Estimation(MLE)와 Maximum A Posterior(MAP)
- MLE는 Likelihood 함수의 최대값을 찾는 방범임

- MLE를 가우시안 분포로 가정하고 풀면 MSE와 동치

- MLE를 베르누이 분포로 가정하고 풀면 CE와 동치

- Likelihood는 지금 얻은 데이터가 이 분포로부터 나왔을 가능도를 말함, 즉 Likelihood 함수는 각 데이터 샘플에서 현재 추정하고자 하는 분포에서 나올 가능도를 계산하여 이들을 모두 곱한 것임

- 관찰을 통해서도 Likelihood를 계산할 수 있지만, Likelihood 함수를 단순히 정해지지 않은 몇 개의 parameter로 이루어진 함수로 모델링을 한 후에, 이 모델이 주어진 Data를 가장 잘 설명하도록 parameter들을 구해내며, Likelihood 함수의 최대값을 찾을 수 있고, 이러한 방법이 바로 딥러닝임

- MLE를 사용하여 우리는 주어진 데이터를 가지고 Likelihood 함수를 최대값으로 만들 수 있는 파라미터를 얻고자 모델의 가중치를 업데이트 해나가며, 최적의 가중치를 찾아나감

- 일반적인 딥러닝에서 MLE의 Likelihood 함수는 가중치를 모르기 때문에, 가중치에 대한 함수값으로 표현이 됨

- 사후확률은 데이터가 주어졌을 때의 가중치의 분포, 사전확률은 가중치에 대한 확률 값, Likelihood 함수는 가중치가 주어졌을 때의 데이터의 분포 값

- 각 샘플들의 Likelihood 값은 서로 독립적이기 때문에 Likelihood를 계산할 때 서로 곱하게됨, 그런데 곱하면 값이 너무 커지기 때문에 우리는 log를 취해줌으로써 덧셈으로 변경함

- Deep Learning 등에서 L2 Loss를 이용한다는 것은 주어진 Data로부터 얻은 Likelihood를 최대화시키겠다는 뜻으로 해석할 수 있음, 즉 L2 Loss를 최소화 시키는 일은 Likelihood를 최대화 시키는 일인 것

- MAP는 사후확률은 최대화 시키는 방법임

- 우리는 사후확률을 계산할 때 Likelihood와 사전 확률은 같이 사용함, 즉 MAP는 Likelihood와 사전 확률은 같이 사용하여 사후확률은 최대화함

- 딥러닝에서 MAP를 사용하는 것은 사전 확률이 결국 파라미터에 대한 확률값을 의미하기 때문에 Weight Decay(Regularization)라는 방식으로 사용됨

- L2 Regularization을 쓴다는 것은 주어진 Data를 적용함과 동시에 w에 Gaussian Distribution이라는 Prior를 걸어 주어 MAP를 통해 w를 구하겠다는 것으로 해석할 수 있음

- L1 Regularization을 쓴다는 것은 주어진 Data를 적용함과 동시에 w에 Laplacian Distribution이라는 Prior를 걸어 주어 MAP를 통해 w를 구하겠다는 것으로 해석할 수 있음

- 구하고자 하는 대상을 철저히 데이터만을 이용해서 구하고 싶다면 MLE를 이용하는 것

- 데이터와 더불어 우리가 갖고 있는 사전 지식까지 반영하고 싶다면 MAP를 이용하는 것(사전 지식에 어떻게 보면 output에 대한 특정 제약 조건이라고 볼 수 있음)

- 어떤 함수의 최대값을 찾는 방법 중 가장 보편적인 방법은 미분계수를 이용하는 것이고, 우리는 MAE, MAP의 식을 경사하강법을 이용하여 최대가 되는 가중치(모수)를 찾을 수 있음

## Entorpy와 정보 이론
- 정보 이론에서 정보는 특정한 관찰에 의해 얼마 만큼의 정보를 흭득했는지 수치로 정량화한 값을 의미함 

- 따라서 놀랄만한 내용일 수록, 발생할 확률이 낮은 사건 일 수록 정보량이 많다고 함. 왜냐하면 직관적으로 생각해보더라도 매번 나오는 정보보다 어쩌다 한번 우리에게 주어진 정보가 그 가치가 더 크며, 이는 우리에게 더 큰 정보를 줄 수 있다고 볼 수 있음

- 통계학에서는 엔트로피를 평균 정보량(정보량의 기댓값, 해당 사건이 발생할 확률과 사건을 곱하고 그 값을 모두 합친 값), 즉 정보의 불확실성이라고 표현함

- 따라서 엔트로피가 크다는 것은 정보의 불확실성이 크다는 것을 의미하고 이는 특정 사건이 발생할 확률이 고르다고 표현할 수 있음. 왜냐하면 사건들의 발생할 확률이 고르다면 그 만큼 우리가 원하는 정답을 얻기 위해 많은 관찰을(모든 사건을 여러번 확인해봐야함) 해야하기 때문임

- 반대로 엔트로피가 작다는 것은 정보의 불확실설이 작다는 것을 의미하고 이는 특정 사건이 발생할 확률이 고르지 않다고 표현할 수 있음(발생할 확률이 매우 낮은 사건이 존재하거나 발생활 확률이 매우 높은 사건이 존재함). 왜냐하면 특정 사건이 발생할 확률이 높다면 우리는 그 사건을 제외하고 새로운 사건을 탐색할 수 있기 때문임

- 즉, 정보의 불확실성이 낮다는 것은 탐색하려는 사건들이 발생할 확률이 고르지 않다는 것을 의미하고, 정보의 불확실성이 크다는 것은 탐색하려는 사건들이 발생할 확률이 고르다는 것을 의미함(이산확률변수일 때는 균일 분포일때, 연속확률변수일 때는 정규 분포일 때)

- 정보의 불확실성이 낮음(엔트로피가 작음, 정보량이 많음) -> 발생할 확률이 매우 높거나 낮은 사건들이 존재함 -> 발생할 확률이 낮은 사건을 통해서 많은 양의 정보를 얻을 수 있음(무엇이 중요한 사건인지 알기 수월함)

- 정보의 불확실성이 높음(엔트포피가 높음, 정보량이 적음) -> 발생할 확률이 서로 엇비슷한 사건들이 많이 존재함 -> 모든 사건으로 부터 얻을 수 있는 정보량이 비슷함(무엇이 중요한 사건인지 알기 어려움)

## Cross Entropy
- 크로스 엔트로피는 한마디로 하면 예측과 달라서 생기는 정보량이라고 할 수 있음
- 크로스 엔트로피는 타겟값과 모델의 출력값이 얼마나 다른지 알려주는 식이며, Target을 정확하게 맞추면 크로스 엔트로피의 값은 낮아짐(이상적인 정보에 점차 다가가고 있음)

## KL-Divergence
- 두 확률 분포간의 차이를 계산하는 방법
- 두 확률 분포를 A와 B라고 한다면 A를 기준으로 볼 때의 B에 대한 크로스 엔트로피를 구하고, A에 대한 크로스 엔트로피를 구해서, 두 값 간의 차이를 계산함.
- 두 값의 차이가 만약 0에 가까워 진다면 두 확률 분포 간의 차이가 없다는 것을 의미함

## MSE와 MAE
- MSE는 잔차의 제곱의 합을 구하는 방법임
- 잔차의 제곱의 합은 실제 값들이 우리가 예측한 값보다 얼마나 멀리 떨어져 있는가를 의미함
- 따라서 잔차의 제곱의 합이 의미하는 것은 y에 대한 조건부 분산임
- 그리고 조건부 분산이 최소가 되는 값이 결국 평균이며, 회귀 계수의 목표는 조건부 평균을 구하는 것이 때문에 MSE를 최소화함으로써 우리는 조건부 평균을 구하여 회귀 모델을 얻을 수 있는 것임
- 정리하면 MSE를 최소화 하는 것은 조건부 평균을 구하는 것이라고 할 수 있음

- MAE는 잔차의 절대값에 합을 구하는 방법임
- MAE가 최소가 되는 값은 중앙값이며, 이는 조건부 중앙값을 구하는 방법이라고 할 수 있음

- 따라서 평균과 중앙값의 특성에 따라서 MAE가 MSE보다 아웃라이어에 더 강건하다는 것을 유추할 수 있음
- 그럼에도 MSE를 사용하는 이유는 평균을 추정함으로써 우리는 통계학에서 사용되는 다양한 방법을 적용할 수 있기 때문임(중심극한정리 등)

## 다중공선성
- 다중공선성이란 여러 독립변수들이 서로 강한 상관 관계를 갖고 있는 상태(통계적  관점)

- 다중공선성이란 여러 개의 벡터가 선형적으로 같은 방향을 가리키고 있는 문제(선형대수학 관점)

- 선형 회귀 모델은 독립변수들이 서로 독립이어야 하다는 가정이 있는데, 이 가정을 위배하기 때문에 문제가 발생하는 것

- 다중공선성은 회귀 모델에 어떤 변수가 포함되는지 여부에 따라 특정 변수의 회귀 계수 값이 크게 변동할 가능성이 높으며, 회귀 계수의 표준 오차가 커져서 통계적 유의성에 영향을 줌
- 따라서 다중공선성은 독립 변수의 회귀 계수 추정에 영향을 줄 뿐, 모델의 종속변수 예측에는 영향을 주지 않음

- 변수간의 다중공선성이 발생한다고 해서 무조건 적으로 제거하는 것은 좋지 못한 방법임, 가령 음주와 흡연을 가지고 암 발생 확률을 예측한다고 할 때, 음주와 흡연간에 다중공선성이 존재하여 하나의 변수를 제거 후에 모델을 만든다면 이는 적합한 모델을 만드는 것이라고 볼 수 없음

- 이처럼 무조건 다중공선성이 발생한다고 해서 변수를 무조건 적으로 제거하는 것이 아니라, 도메인 지식에 근거하여 변수를 선택하거나, 종속 변수간의 인과 관계를 고려하는 것이 더 적합한 방법이라고 할 수 있음

- 아니면 PCA 등의 방법을 이용하여 변수를 축소하는 것도 괜찮은 대안이 될 수 있음

- 결론은 회귀 계수 추정이 아닌 예측이 중요한 경우라면 다중공선성이 존재하는 변수를 무조건 제거할 필요가 없으며, 제거해야하는 경우에는 도메인 지식에 근거하여 변수를 제거하는 것이 합당한 방법임

## 변수 선택법
- 대표적인 변수 선택법으로는 Step-wise 변수 선택법이 있음, 이는 다양한 변수 간의 조합을 고려하여 최적의 예측 결과를 내는 변수를 선택하능 방법임

- 그런데 Step-wise 기법이 무조건적으로 최적의 변수 조합을 선택한다는 보장이 없음, 경험적으로 변수를 조합하여 최적의 모델을 찾을 때 보다, 모든 변수를 활용하는 것이 좀더 강건한 모델이 만들어졌으며, 조사에 따르면 Step-wise 기법은 회귀 계수 추정이 불안정하기 때문에 적합한 방법이 아니라고 함

- 직관적으로 생각해보더라도 단계 선택법 자체가 해당 표본을 가장 잘 설명할 수 있는 변수를 선택하기 때문에 모집단을 가장 잘 설명할 수 있는 변수라는 것을 보장해주지는 않음

- 단순히 표본에 과적합된 변수 선택이라고도 볼 수 있음

- 따라서 완전히 변수 선택을 하지 않거나, 전문가 지식을 활용하거나, 여러 개의 후보 모델을 생성한 후 각 모델의 회귀 계수의 가중 평균을 구하여 최종 모델을 생성하거나, 교차 검증을 이용해 모델 생성과 검정에 사용하는 샘플 집합을 다르게 하여 조금더 강건한 모델을 만드는 것도 방법임

- 또는 회귀 계수에 제약 조건을 주는 규제 기법을 적용하는 것도 좋은 방법일 수도 있음(L1, L2)

## Overfitting과 Underfitting
- Overfitting은 모델링 대상을 설명하는데 불필요한 noise를 과도하게 모델이 반영한 상태를 의미함

- Underfitting은 모델링 대상을 설명하기에 필요한 signal을 충분히 모델이 반영하지 못한 상태를 의미함

- 모델이 복잡하면 Overfitting이 발생할 가능성이 높고, 모델이 단순하면 Underfitting이 발생할 가능성이 높다고 표현함

- 하지만 과적합과 과소적합은 단순히 모델의 복잡도에만 영향을 받는 것이 아니라 학습에 사용되는 데이터의 질에도 영향을 받음

- 모델링이란 데이터에서 특정한 정보를 추출하여, 어떠한 규칙을 만들어 나가는 것이라고 할 수 있음, 이 규칙을 만들어 나가는 과정에 다양한 알고리즘이 존재함(딥러닝, 선형 회귀, 랜덤 포레스트 등)

- 여기서 모델에 필요한 정보를 signal, 불필요한 정보를 noise라고 할 수 있음

- 따라서 우리는 우선적으로 데이터를 분석하여 사용하는 데이터에 signal과 noise 중 어떤 정보를 많이 포함하고 있는지 판단하고, 이를 바탕으로 signal 정보를 더 얻기 위해 데이터를 더 수집할 지, 아니면 signal 정보 증가시키고 noise 정보를 제거하기 위해서 데이터 전처리 등을 할 수도 있음

- 이렇게 데이터를 분석하여 우선적으로 모델이 예측에 필요한 정보가 많이 포함되어 있는지를 판단한 후에 모델링에 들어가는 것이 Overfitting or Underfitting 을 줄이기 위한 방법임

- 데이터에 이미 충분히 많은 signal 정보가 들어있다면, 우리는 이제 모델링 기법을 통해서도 Overfitting or Underfitting 을 줄일 수도 있음

- 결론은 Overfitting or Underfitting 을 줄이기 위해서는 모델링만 분석하는 것이 아니라 데이터도 함께 분석해야 한다는 것임

## 회귀 분석
- 회귀 모델은 한 마디로 정의하면 에측하고자 하는 값에 영향을 주는 조건들을 고려하여 구한 평균을 선으로 표현한 것(조건부 평균)
- 회귀 분석에서 말하는 회귀란 잔차가 평균으로 회귀하는 것을 의미하며, 이에 회귀 모델은 잔차가 평균으로 회귀하도록 만든 모델이라고 할 수 있음
- 따라서 회귀 모델에서는 잔차가 중요하다는 것을 알 수 있고, 이에 우리는 회귀 모델이 적합한지에 대한 기준을 잔차와 관련된 여러 가정을 세우고 해당 가정이 맞는지를 판단하여 회귀 모델의 적합도를 검사하게 됨
- 잔차의 분포는 정규 분포이어야 하며(정규성), 잔차는 독립 변수들과 자기 자신과에 상관성이 없어야 하며(독립성), 잔차의 분포는 일정해야 함(등분산성)
- 잔차의 분포가 정규 분포가 되면 회귀 모델에 정의였던 잔차는 평균으로 회귀할 가능성이 높아짐
- 잔차가 독립성을 만족하면 어떠한 데이터의 특성에 영향을 받지 않는다는 것을 의미하기 때문에 잔차의 특성을 그대로 표현하게 되어 잔차는 평균으로 회귀할 가능성이 높아짐
- 잔차의 분포가 일정하지 않다면, 즉 x 값이 커질수록 잔차가 증가하는 경향을 보인다면 x 값이 커질 수록 잔차는 평균에서 크게 벗어날 확률이 커지기 때문에 잔차의 분포가 일정해야 잔차는 평균으로 회귀할 가능성이 높아짐
- 추가적으로 고전적인 선형 회귀는 독립변수와 종속변수간의 선형관계를 가져야하고, 독립변수 간에는 서로 선형적으로 독립이다라는 가정도 필요함
- 그리고 위에 맞지 않는 가정을 가진 데이터를 가지고 회귀 모델을 만든다면 각각의 가정을 바꾸어 만든 회귀 모델을 사용하면 됨(Auto-Regression 모델, Lasso, Ridge, MAE를 사용한 모댈 등)

## R-square
- 결정계수는 회귀 모델에서 독립변수가 종속변수를 얼마만큼 설명해 주는지를 가리키는 지표

## log를 사용하는 이유
- log를 취하게 되면 큰 값으로 갈수록 작은 값과의 차이의 크기가 줄어듬, 즉 큰 값으로 갈 수록 그 값의 크기가 더 많이 작아지는 것임
- 이러한 특징 때문에 비대칭 분포의 데이터에 log를 취함으로써 정규 분포와 유사하게 만들어줌
- 예를 들어 정규화와 표준화는 그 값의 분포 자체를 건들지는 않음, 그러나 로그는 값의 작은 값부터 큰 값의 크기에 변형을 가함으로써 데이터의 분포 자체가 변하게 됨

## likelihood와 probability의 차이
- probability는 parameter를 상수로 가정하여, parameter가 주어졌을 때 관측된 사건이 발생할 가능성을 의미함(특정 확률 분포를 가정하여 접근함)

- likelihood는 parameter를 변수로 가정하여, parameter가 주어졌을 때 관측된 사건이 발생할 가능성을 의미함(특정 확률 분포를 가정하지 않고 접근함)

- likelihood의 경우 parameter를 변수로 가정하기 때문에 데이터를 바탕으로 관측된 사건들이 발생할 확률을 최대화 할 수 있는 함수를 추정할 수 있음

- 따라서 우리는 Likelihood 함수의 최대값을 찾는 방범인 MLE를 이용해 현재 주어진 데이터를 가장 잘 설명할 수 있는 분포를 추론할 수 있게됨

## Sampling과 Resampling
- Sampling은 모집단에서 임의 표본을 뽑아내는 것으로, 간단하게 말하면 표본 추출을 의미함
- Resampling은 내가 가지고 있는 데이터, 즉 표본에서 다시 샘플의 부분 집합을 뽑는 것을 의미함
- Resampling을 이용한 대표적인 방법이 Bootstrap과 k-fold 방법임

## Bootstrap
- Bootstrap은 현재 가지고 있는 데이터, 즉 표본에서 복원 추출을 통해서 다양한 샘플의 부분 집합을 뽑는 방식을 의미함
- Bootstrap이 좋은 성능을 가져다주는 이유는 다양성이 반영될 수 있기 때문이라고 생각함
- 표본에서 복원 추출된 다양한 샘플들도 어떻게 보면 하나의 모집단에서 나온 다양한 표본이라고 볼 수 있음
- 표본 데이터가 많아지는 만큼 모집단의 모수를 추정하기 위한 다양한 정보를 얻을 수 있고, 이를 앙상블 함으로써 조금 더 정확하게 값을 추정할 수 있는 것이라고 생각됨
- 표본 데이터로 다양한 표본 데이터를 생성하여 모집단의 모수를 추정하기 위한 샘플셋을 늘려주기 때문에 성능이 좋아지는 것이라고 정리할 수 있겠음

## A/B Test
- A/B 테스트는 기존 서비스(A)와 새로 적용하고 싶은 서비스(B)를 통계적인 방법으로 비교하여 새로운 서비스가 기존 서비스에 비해 정말 효과가 있는지를 알아보는 방법

- A와 B군 간에 사람이 구분하기 어려울 정도로 비슷하게 집단을 나눠야 함

- 같은 실험에서는 유저를 항상 동일한 그룹에 배정해야 함

- 같은 유저라도 실험이 바뀌면 새롭게 그룹을 배정해야 함

- A그룹과 B그룹은 서로에게 영향을 미쳐서는 안됨

- 의사결정이 가능할 정도로 충분히 많은 데이터를 확보해야 함

- 대상자가 실험 여부를 인지하게 되면 편향이 발생할 수 있기 때문에 주의해야 함

- A와 B간의 사이에 차이가 없을 것이라고 최대한 보수적으로 귀무가설 설정 -> 유의수준을 설정하고 실험을 수행 -> 실험이 끝나고 p-value를 계산하여 유의 수준과 비교 (아주 간단한 방식)

- A/B 테스트는 돌리기만 하면 성과가 나오는 마법의 도구가 아님

- 신뢰할 수 있는 실험 결과를 얻기 위해서는 많은 고민이 필요함

- A/B 테스트를 고객을 이해하기 위한 과정으로 활용할 수도 있음

- A/B 테스트를 하는 기간 동안에는 최대 보상을 얻을 수 있다고 보장할 수 없음, 왜냐하면 A안이 최고라면 우리는 이미 B안을 고객에 제공해줌으로써 보상을 잃게됨, 이처럼 A/B 테스트는 실험을 진행하는 기간도 중요함, 아니면 MAB와 같은 방식으로 A/B Test를 진행할 수도 있음

## 참고 자료
- https://angeloyeo.github.io/
- https://hyeongminlee.github.io/
- https://darkpgmr.tistory.com/
- https://brunch.co.kr/@seoungbumkim/7
- https://icim.nims.re.kr/post/easyMath
- https://brunch.co.kr/@gimmesilver#articles