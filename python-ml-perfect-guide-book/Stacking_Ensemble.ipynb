{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Stacking Ensemble.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPtMuBTJvYiUjpVYbgrW5pR"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Du3dAX_9DS9"
      },
      "source": [
        "# 기본적인 Stacking\r\n",
        "\r\n",
        "1. 학습 데이터로 개별 모델을 학습한다.\r\n",
        "2. 테스트 데이터로 개별 모델의 예측 값을 구한다.\r\n",
        "3. 개별 모델의 예측 값들을 메타 모델의 학습 데이터로 활용해 모델을 학습한다.\r\n",
        "4. 학습된 메타 모델에 개별 모델의 예측 값들들 넣어 최종 예측을 한다.\r\n",
        "\r\n",
        "결론은 개별 모델의 예측 값이 학습 데이터가 된다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tPx6DasW13Nm"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "cancer_data = load_breast_cancer()\n",
        "\n",
        "X_data = cancer_data.data\n",
        "y_label = cancer_data.target\n",
        "\n",
        "X_train , X_test , y_train , y_test = train_test_split(X_data , y_label , test_size=0.2 , random_state=0)"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZYBwqil113Nt"
      },
      "source": [
        "# 개별 ML 모델을 위한 Classifier 생성.\n",
        "knn_clf  = KNeighborsClassifier(n_neighbors=4)\n",
        "rf_clf = RandomForestClassifier(n_estimators=100, random_state=0)\n",
        "dt_clf = DecisionTreeClassifier()\n",
        "ada_clf = AdaBoostClassifier(n_estimators=100)\n",
        "\n",
        "# 최종 Stacking 모델을 위한 Classifier생성. \n",
        "lr_final = LogisticRegression(C=10)\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ylGm9mVs13Nu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb81e4f3-2c86-4936-a438-a50677df88a1"
      },
      "source": [
        "# 개별 모델들을 학습. \n",
        "knn_clf.fit(X_train, y_train)\n",
        "rf_clf.fit(X_train , y_train)\n",
        "dt_clf.fit(X_train , y_train)\n",
        "ada_clf.fit(X_train, y_train)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1.0,\n",
              "                   n_estimators=100, random_state=None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BgWFXhyc13Nv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e6b1b066-935e-418e-ccb7-1d50aa4ed76a"
      },
      "source": [
        "# 학습된 개별 모델들이 각자 반환하는 예측 데이터 셋을 생성하고 개별 모델의 정확도 측정. \n",
        "knn_pred = knn_clf.predict(X_test)\n",
        "rf_pred = rf_clf.predict(X_test)\n",
        "dt_pred = dt_clf.predict(X_test)\n",
        "ada_pred = ada_clf.predict(X_test)\n",
        "\n",
        "print('KNN 정확도: {0:.4f}'.format(accuracy_score(y_test, knn_pred)))\n",
        "print('랜덤 포레스트 정확도: {0:.4f}'.format(accuracy_score(y_test, rf_pred)))\n",
        "print('결정 트리 정확도: {0:.4f}'.format(accuracy_score(y_test, dt_pred)))\n",
        "print('에이다부스트 정확도: {0:.4f} :'.format(accuracy_score(y_test, ada_pred)))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "KNN 정확도: 0.9211\n",
            "랜덤 포레스트 정확도: 0.9649\n",
            "결정 트리 정확도: 0.9123\n",
            "에이다부스트 정확도: 0.9561 :\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JpwNRFSi13Nv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "573afac2-8897-4cd6-c439-d8afd707bd71"
      },
      "source": [
        "pred = np.array([knn_pred, rf_pred, dt_pred, ada_pred])\n",
        "print(pred.shape)\n",
        "\n",
        "# transpose를 이용해 행과 열의 위치 교환. 컬럼 레벨로 각 알고리즘의 예측 결과를 피처로 만듦. \n",
        "pred = np.transpose(pred)\n",
        "print(pred.shape)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(4, 114)\n",
            "(114, 4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ERRQ3J3813Nv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca7a1871-1786-47b6-ee71-c79a5fd92275"
      },
      "source": [
        "lr_final.fit(pred, y_test)\n",
        "final = lr_final.predict(pred)\n",
        "\n",
        "print('최종 메타 모델의 예측 정확도: {0:.4f}'.format(accuracy_score(y_test , final)))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "최종 메타 모델의 예측 정확도: 0.9737\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ptKepree13Nw"
      },
      "source": [
        "### CV 셋 기반의 Stacking\r\n",
        "\r\n",
        "- 주어진 데이터\r\n",
        " - 학습 데이터 => KFold로 나누어진 학습 데이터 + 검증용 데이터\r\n",
        " - 테스트 데이터\r\n",
        "\r\n",
        "1.KFold로 나누어진 학습 데이터로 각각의 모델을 학습한다.\r\n",
        "\r\n",
        "2-1. 학습된 모델에 검증 데이터로 값을 예측한다. -> 검증데이터로 만들어진 전체 학습 데이터 크기의 예측 데이터\r\n",
        "\r\n",
        "2-2. 학습된 모델에 테스트 데이터로 값을 예측한다. -> 테스트 데이터로 만들어진 예측 데이터\r\n",
        "\r\n",
        "3.메타 모델에 검증데이터로 만들어진 전체 학습 데이터 크기의 예측 데이터로 학습시킨다.\r\n",
        "\r\n",
        "4.학습된 메타 모델에 테스트 데이터로 만들어진 예측 데이터로 최종 예측 값을 구한다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ROaioGM613Nw"
      },
      "source": [
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "\n",
        "# 개별 기반 모델에서 최종 메타 모델이 사용할 학습 및 테스트용 데이터를 생성하기 위한 함수. \n",
        "def get_stacking_base_datasets(model, X_train_n, y_train_n, X_test_n, n_folds ):\n",
        "    # 지정된 n_folds값으로 KFold 생성.\n",
        "    kf = KFold(n_splits=n_folds, shuffle=False, random_state=0)\n",
        "    #추후에 메타 모델이 사용할 학습 데이터 반환을 위한 넘파이 배열 초기화 \n",
        "    train_fold_pred = np.zeros((X_train_n.shape[0] ,1 ))\n",
        "    test_pred = np.zeros((X_test_n.shape[0],n_folds))\n",
        "    print(model.__class__.__name__ , ' model 시작 ')\n",
        "    \n",
        "    for folder_counter , (train_index, valid_index) in enumerate(kf.split(X_train_n)):\n",
        "        #입력된 학습 데이터에서 기반 모델이 학습/예측할 폴드 데이터 셋 추출 \n",
        "        print('\\t 폴드 세트: ',folder_counter,' 시작 ')\n",
        "        X_tr = X_train_n[train_index] \n",
        "        y_tr = y_train_n[train_index] \n",
        "        X_te = X_train_n[valid_index]  \n",
        "        \n",
        "        #폴드 세트 내부에서 다시 만들어진 학습 데이터로 기반 모델의 학습 수행.\n",
        "        model.fit(X_tr , y_tr)       \n",
        "        #폴드 세트 내부에서 다시 만들어진 검증 데이터로 기반 모델 예측 후 데이터 저장.\n",
        "        train_fold_pred[valid_index, :] = model.predict(X_te).reshape(-1,1)\n",
        "        #입력된 원본 테스트 데이터를 폴드 세트내 학습된 기반 모델에서 예측 후 데이터 저장. \n",
        "        test_pred[:, folder_counter] = model.predict(X_test_n)\n",
        "            \n",
        "    # 폴드 세트 내에서 원본 테스트 데이터를 예측한 데이터를 평균하여 테스트 데이터로 생성 \n",
        "    test_pred_mean = np.mean(test_pred, axis=1).reshape(-1,1)    \n",
        "    \n",
        "    #train_fold_pred는 최종 메타 모델이 사용하는 학습 데이터, test_pred_mean은 테스트 데이터\n",
        "    return train_fold_pred , test_pred_mean"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WqXOKkCy91Ki"
      },
      "source": [
        "# 개별 ML 모델을 위한 Classifier 생성.\n",
        "knn_clf  = KNeighborsClassifier(n_neighbors=4)\n",
        "rf_clf = RandomForestClassifier(n_estimators=100, random_state=0)\n",
        "dt_clf = DecisionTreeClassifier()\n",
        "ada_clf = AdaBoostClassifier(n_estimators=100)\n",
        "\n",
        "# 최종 Stacking 모델을 위한 Classifier생성. \n",
        "lr_final = LogisticRegression(C=10)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SVEMSGS_13Nw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f64e33c0-6e45-47b5-82d7-540bdf646e5e"
      },
      "source": [
        "knn_train, knn_test = get_stacking_base_datasets(knn_clf, X_train, y_train, X_test, 7)\n",
        "rf_train, rf_test = get_stacking_base_datasets(rf_clf, X_train, y_train, X_test, 7)\n",
        "dt_train, dt_test = get_stacking_base_datasets(dt_clf, X_train, y_train, X_test,  7)    \n",
        "ada_train, ada_test = get_stacking_base_datasets(ada_clf, X_train, y_train, X_test, 7)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
            "  FutureWarning\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
            "  FutureWarning\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "KNeighborsClassifier  model 시작 \n",
            "\t 폴드 세트:  0  시작 \n",
            "\t 폴드 세트:  1  시작 \n",
            "\t 폴드 세트:  2  시작 \n",
            "\t 폴드 세트:  3  시작 \n",
            "\t 폴드 세트:  4  시작 \n",
            "\t 폴드 세트:  5  시작 \n",
            "\t 폴드 세트:  6  시작 \n",
            "RandomForestClassifier  model 시작 \n",
            "\t 폴드 세트:  0  시작 \n",
            "\t 폴드 세트:  1  시작 \n",
            "\t 폴드 세트:  2  시작 \n",
            "\t 폴드 세트:  3  시작 \n",
            "\t 폴드 세트:  4  시작 \n",
            "\t 폴드 세트:  5  시작 \n",
            "\t 폴드 세트:  6  시작 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
            "  FutureWarning\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
            "  FutureWarning\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "DecisionTreeClassifier  model 시작 \n",
            "\t 폴드 세트:  0  시작 \n",
            "\t 폴드 세트:  1  시작 \n",
            "\t 폴드 세트:  2  시작 \n",
            "\t 폴드 세트:  3  시작 \n",
            "\t 폴드 세트:  4  시작 \n",
            "\t 폴드 세트:  5  시작 \n",
            "\t 폴드 세트:  6  시작 \n",
            "AdaBoostClassifier  model 시작 \n",
            "\t 폴드 세트:  0  시작 \n",
            "\t 폴드 세트:  1  시작 \n",
            "\t 폴드 세트:  2  시작 \n",
            "\t 폴드 세트:  3  시작 \n",
            "\t 폴드 세트:  4  시작 \n",
            "\t 폴드 세트:  5  시작 \n",
            "\t 폴드 세트:  6  시작 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iI51zFDI13Nx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c2e975a-ab6f-4dd6-dcd5-2d07629d9c47"
      },
      "source": [
        "Stack_final_X_train = np.concatenate((knn_train, rf_train, dt_train, ada_train), axis=1)\n",
        "Stack_final_X_test = np.concatenate((knn_test, rf_test, dt_test, ada_test), axis=1)\n",
        "print('원본 학습 피처 데이터 Shape:',X_train.shape, '원본 테스트 피처 Shape:',X_test.shape)\n",
        "print('스태킹 학습 피처 데이터 Shape:', Stack_final_X_train.shape,\n",
        "      '스태킹 테스트 피처 데이터 Shape:',Stack_final_X_test.shape)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "원본 학습 피처 데이터 Shape: (455, 30) 원본 테스트 피처 Shape: (114, 30)\n",
            "스태킹 학습 피처 데이터 Shape: (455, 4) 스태킹 테스트 피처 데이터 Shape: (114, 4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i4BZ8S0L13Nx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "429818b9-c1ea-41bd-e2fc-42144fed704f"
      },
      "source": [
        "lr_final.fit(Stack_final_X_train, y_train)\n",
        "stack_final = lr_final.predict(Stack_final_X_test)\n",
        "\n",
        "print('최종 메타 모델의 예측 정확도: {0:.4f}'.format(accuracy_score(y_test, stack_final)))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "최종 메타 모델의 예측 정확도: 0.9737\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}